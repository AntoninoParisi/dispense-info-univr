\documentclass[a4paper, 11pt]{article}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{frontespizio}
\usepackage{hyperref}
\hypersetup{hidelinks,
	colorlinks = true,
	urlcolor = black, 
	linkcolor = black}
\usepackage[margin=3cm]{geometry}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{stmaryrd}
\usepackage{semantic}
\usepackage[strict]{changepage}
\usepackage{xfrac}
\usepackage{cancel}
\usepackage{courier}
\usepackage{mathabx}


\lstset{tabsize=2,
	basicstyle=\small\ttfamily}


\newtheorem{thm}{Teorema}[section]
\newtheorem{definit}{Definizione}[section]

\newcommand{\sem}[1]{\llbracket #1 \rrbracket}
\newcommand{\type}{\Gamma \vdash}
\newcommand{\code}[1]{\textup{\lstinline|#1|}}
\newcommand{\subs}[3]{#1 \lbrace \sfrac{#2}{#3} \rbrace}
\newcommand{\goesto}{\rightarrowtriangle}
\newcommand{\treq}{\simeq_\Gamma^T}
\newcommand{\compar}{\ ||\ }

\begin{document}
	\begin{frontespizio}
		\Preambolo{\usepackage{datetime}}
		\Istituzione{Università degli Studi di Verona}
		\Divisione{Dipartimento di informatica}
		\Titolo{Linguaggi di programmazione}
		\Scuola{}
		\Sottotitolo{Riassunto dei principali argomenti}
		\Candidato{Davide Bianchi}
		\NCandidato{Autore}
		\Annoaccademico{2017/2018}
	\end{frontespizio}
	
	\tableofcontents
	\newpage
	\pagestyle{fancy}
	
	\section{Introduzione}
	Un linguaggio di programmazione è composto da: \begin{itemize}
		\item \textit{Sintassi:} insieme di regole di scrittura del linguaggio;
		\item \textit{Semantica:} descrizione del comportamento del programma a tempo di esecuzione;
		\item \textit{Pragmatica:} descrizione delle caratteristiche del linguaggio, delle sue funzionalità ecc.
	\end{itemize}

	Gli stili per dare la semantica di un linguaggio sono 3:
	\begin{itemize}
		\item \textit{Operazionale}: la semantica è data con sistemi di transizione, fornendo i passi della computazione passo passo;
		\item \textit{Denotazionale}: il significato di un programma è dato dalla struttura di un insieme;
		\item \textit{Assiomatica}: il significato è dato attraverso regole assiomatiche o qualche tipo di logica.
	\end{itemize}

	\section{Esempio di linguaggio basilare}
	La semantica operazionale di un linguaggio è data attraverso un sistema di regole di inferenza, date come segue: \begin{align*}
	(Assioma)\ \frac{-}{(Conclusione)} \qquad (Regola)\ \frac{(Hyp_1)\ (Hyp_2)\ ...\ (Hyp_n)}{(Conclusione)}
	\end{align*}  
	
	Introduciamo la sintassi di un linguaggio basato solo su espressioni aritmetiche:
	\begin{align*}
		E :=\ n\ |\ E\ |\ E+E\ |\ E*E\ ...
	\end{align*}
	
	La valutazione di programmi generati con questa sintassi può procedere in due modi:
	\begin{itemize}
		\item \textit{Small step:} la semantica fornisce il sistema per procedere nell'esecuzione, passo dopo passo;
		\item \textit{Big step:} la semantica va subito al risultato finale.
	\end{itemize}

	\subsection{Semantica big-step}
	Forniamo la semantica big-step per il linguaggio dato sopra:
	\begin{align*}
		\inference[B-Num]{-}{n \Downarrow n} \qquad \inference[B-Add]{E_1 \Downarrow n_1\ E_2 \Downarrow n_2}{E_1 + E_2 \Downarrow n_3}\ n_3 = add(n_1, n_2)
	\end{align*}
	La semantica big-step fornisce immediatamente il risultato, dando subito il valore finale dell'espressione che si sta valutando.
	\subsubsection{Esempio}
	\begin{align*}
		\inference[B-Add]{\inference[B-Num]{-}{3 \Downarrow 3} & \inference[B-Add]{\inference[B-Num]{-}{2 \Downarrow 2} & \inference[B-Num]{-}{1 \Downarrow 1}} {2 + 1 \Downarrow 3}}{3 + (2 + 1) \Downarrow 6}
	\end{align*}
	
	\begin{thm}[Determinatezza per semantica big-step] $E \Downarrow m$ e $E \Downarrow n$ implica $m=n$.
		
	\end{thm}
	
	\subsection{Semantica small-step}
	Indichiamo con $E_1 \rightarrowtriangle E_2$ lo svolgimento di un solo passo di semantica.
	\begin{align*} 
	&\inference[S-Left]{E_1 \rightarrowtriangle E_1'}{E_1 + E_2 \rightarrowtriangle E_1' + E_2} \\
	&\inference[S-N.Right]{E_2 \rightarrowtriangle E_2'}{n_1 + E_2 \rightarrowtriangle n_1 + E_2'} \\
	&\inference[S-Add]{-}{n_1 + n_2 \rightarrowtriangle n_3} n_3 = add(n_1, n_2)
	\end{align*}
	Con queste regole l'ordine di valutazione degli statement è fisso, procede sempre da sinistra verso destra.
	Diamo un'alternativa:
	\begin{align*}
		&\inference[S-Left]{E_1 \rightarrowtriangle_{ch} E_2}{E_1 + E_2 \rightarrowtriangle_{ch} E_1' + E_2} \\
		&\inference[S-Right]{E_2 \rightarrowtriangle_{ch} E_2'}{E_1 + E_2 \rightarrowtriangle_{ch} E_1 + E_2'} \\
		&\inference[S-Add]{-}{n_1 + n_2 \rightarrowtriangle_{ch} n_3} n_3 = add(n_1, n_2)
	\end{align*}
	In questo caso l'ordine di valutazione è arbitrario.
	La notazione utilizzata in generale è la seguente:
	\begin{itemize}
		\item la relazione $\rightarrowtriangle^k$, con $k \in \mathbb{N}$, indica una sequenza di n passi applicando la semantica small-step;
		\item la relazione $\rightarrowtriangle^\ast$, indica una sequenza di derivazione lunga un certo numero di passi. Questa relazione è riflessiva ed è la chiusura transitiva di $\rightarrowtriangle$.
	\end{itemize}
	
	\begin{thm}[Determinatezza per semantica small-step] Definiamo:
		\begin{itemize}
			\item \textbf{strong determinacy:} $E \rightarrowtriangle F$ e $E \rightarrowtriangle G$ implica $F=G$;
			\item \textbf{weak determinacy:} $E \rightarrowtriangle^\ast m$ e $E \rightarrowtriangle^\ast n$ implica $m=n$;
		\end{itemize}
	\end{thm}

\newpage
\section{Linguaggio imperativo} \label{imp}
Definiamo la sintassi di un semplice linguaggio imperativo:
\begin{align*}
	b &:= true\ |\ false \\
	n &:= \lbrace ... -1, 0, 1, 2, ...\rbrace\\
	l &:= \lbrace l_0, l_1, ... \rbrace \\
	op &:= +\ |\ \geq \\
	e &:= n\ |\ b\ |\ e\ op\ e\ |\ \text{if } e \text{ then } e \text{ else } e\ |\ l:=e\ |\ !l\ |\ skip\ |\ e;e\ |\ \text{while } e \text{ do }\ e
\end{align*}

\textbf{Nota:} lo statement $!l$ indica l'intero memorizzato al momento alla locazione $l$. Inoltre il linguaggio non è tipato, quindi sono ammesse le sintassi come $2 \geq\ true$.

\subsection{Memoria}
La memoria è necessaria per poter valutare gli statement di lettura da una locazione. In particolare definiamo \begin{align*}
 dom(f) &= \lbrace a \in A\ |\ \exists b \in B\ s.t.\ f(a)=b \rbrace  \\
 ran(f) &= \lbrace b \in B\ |\ \exists a \in A\ s.t.\ f(a)=b \rbrace
 \end{align*}
 
 Lo store del linguaggio imperativo in questione è un insieme di funzioni parziali che vanno dalle locazioni di memoria nei numeri interi: \[ s: \mathbb{L} \to \mathbb{Z} \]
 
 L'aggiornamento della memoria funziona come segue: \[ s \lbrack l \rightarrow n \rbrack (l') = \begin{cases}
 n &\text{if } l=l' \\
 s(l') &\text{altrimenti}
 \end{cases} \]
 
 \subsection{Sistemi di transizione}
 Le semantiche operazionali sono date attraverso sistemi di transizione, ovvero strutture composte da: \begin{itemize}
 	\item un insieme $Config$ di configurazioni;
 	\item una relazione binaria $\rightarrowtriangle\ \subseteq Config \times Config$;
 \end{itemize}

Per indicare un generale passo di semantica si usa la notazione \[ \langle e, s \rangle \rightarrowtriangle \langle e', s' \rangle \]
che rappresenta una trasformazione di un programma $e$ con una memoria $s$ in un programma $e'$ con memoria associata $s'$.
I singoli passi di computazione sono singole applicazioni di regole della semantica.

\subsection{Semantica small-step su un linguaggio imperativo} \label{rules}
\begin{adjustwidth}{-1.3cm}{}
\begin{align*}
	&\inference[(op+)]{-}{\langle n_1 + n_2, s \rangle \rightarrowtriangle \langle n, s \rangle}\ n = add(n_1, n_2)
	&\inference[(op-geq \footnotemark)]{-}{\langle n_1 \geq n_2, s \rangle \rightarrowtriangle \langle b, s \rangle}\ b = geq(n_1, n_2) \\
		& &\\
	&\inference[(op1)]{\langle e_1, s \rangle \rightarrowtriangle \langle e_1', s' \rangle}{\langle e_1 \text{ op } e_2, s \rangle \rightarrowtriangle \langle e_1' \text{ op } e_2, s' \rangle}  &\inference[(op2)]{\langle e_2, s \rangle \rightarrowtriangle \langle e_2', s' \rangle}{ \langle v \text{ op } e_2, s \rangle \rightarrowtriangle \langle v \text{ op } e_2', s' \rangle} \\
		& &\\
	&\inference[(deref)]{-}{\langle !l, s \rangle \rightarrowtriangle \langle n,s \rangle}\text{ if } l \in dom(s) \text{ and } s(l)=n &\inference[(assign1)]{-}{\langle l:=n,s \rangle \rightarrowtriangle \langle skip, s\lbrack l \to n\rbrack \rangle}\ \text{if } l \in dom(s) \\
		& &\\ 
	&\inference[(assign2)]{\langle e, s \rangle \rightarrowtriangle \langle e', s' \rangle}{\langle l:=e,s \rangle \rightarrowtriangle \langle l := e', s' \rangle} &\inference[(if-tt)]{-}{\langle \text{if true then } e_1 \text{ else } e_2, s \rangle \rightarrowtriangle \langle e_1, s \rangle} \\
	& & \\
	&\inference[(if-ff)]{-}{\langle \text{if false then } e_1 \text{ else } e_2, s \rangle \rightarrowtriangle \langle e_2, s \rangle} &\inference[(if)]{\langle e, s \rangle \rightarrowtriangle \langle e', s' \rangle}{\langle \text{if } e \text{ then } e_1 \text{ else } e_2, s \rangle \rightarrowtriangle \langle \text{if } e' \text{ then } e_1 \text{ else } e_2, s' \rangle} \\
	& & \\
	&\inference[(seq)]{\langle e_1, s \rangle \rightarrowtriangle \langle e_1', s' \rangle}{\langle e_1;e_2, s \rangle \rightarrowtriangle \langle e_1';e_2, s' \rangle} & \inference[(seq.skip)]{-}{\langle skip; e_2, s \rangle \rightarrowtriangle \langle e_2,s \rangle} \\
	\end{align*}
	\begin{align*}
	& \inference[(while)]{-}{ \langle \text{while } e \text{ do } e_1,s \rangle \rightarrowtriangle \langle \text{if } e \text{ then } (e_1; \text{while } e \text{ do } e_1) \text{ else } skip,s \rangle} \\
\end{align*}
\end{adjustwidth}
\footnotetext{Problemi con \LaTeX\ implicano l'uso di un nome diverso.}

\subsection{Esecuzione di programmi e proprietà}
L'esecuzione di programmi con questa semantica consiste nel trovare una memoria $s'$ tale per cui valga che \[ \langle P, s \rangle \rightarrowtriangle^\ast \langle v, s' \rangle \] ovvero che si raggiunga una configurazione terminale in un certo numero di passi.

Illustriamo inoltre due importanti proprietà:
\begin{thm}[Strong normalization]
	Per ogni memoria $s$ e ogni programma $P$  esiste una qualche memoria $s'$ tale che \[ \langle P,s \rangle \rightarrowtriangle^\ast \langle v,s' \rangle  \]
\end{thm}

\begin{thm}[Determinatezza]
	Se $\langle e,s \rangle  \rightarrowtriangle \langle e_1, s_1 \rangle $ e $\langle e,s \rangle  \rightarrowtriangle \langle e_2, s_2 \rangle $ allora $\langle e_1, s_1 \rangle = \langle e_2, s_2 \rangle$.
\end{thm}

\subsection{Funzione di valutazione della semantica}
Date le regole nella sezione \ref{rules}, possiamo dire che in generale, per valutare una porzione di programma, viene applicata la regola \[ \sem{-}: Exp \to (Store \rightharpoonup Store) \]
dove, data una generica espressione $e$, la funzione $\sem{ \cdot}$ prende una memoria e ne ritorna una aggiornata dopo la valutazione di $e$.

\[ \sem{e}(s) = \begin{cases}
s' &\text{se } \langle e,s \rangle \rightarrowtriangle \langle e',s' \rangle \\
undefined &\text{altrimenti}
\end{cases} \]

\subsection{Possibili varianti del linguaggio}
Nel linguaggio illustrato possono essere introdotte anche diverse varianti.

\subsubsection{Inversione dell'ordine di valutazione}
È possibile ad esempio introdurre un ordine di valutazione \textit{right-to-left}, ossia:
\begin{align*}
	&\inference[(op1b)]{\langle e_2,s \rangle \to \langle e_2', s' \rangle}{\langle e_1 + e_2, s \rangle \rightarrowtriangle \langle e_1 + e_2', s' \rangle}
	&\inference[(op2b)]{\langle e_1,s \rangle \to \langle e_1', s' \rangle}{\langle e_1 + v, s \rangle \rightarrowtriangle \langle e_1' + v, s' \rangle}
\end{align*}
Aggiungendo queste due regole alla semantica ovviamente salta la regola della determinatezza.

\subsubsection{Regole di assegnamento}
Una piccola variante alla regola dell'assegnamento: \begin{align*}
	&\inference[(assign1b)]{-}{\langle l:=n,s \rangle \rightarrowtriangle \langle n, s\lbrack l \to n\rbrack \rangle}\ \text{if } l \in dom(s)
	&\inference[(seq.skip.b)]{-}{\langle v;e_2, s \rangle \rightarrowtriangle \langle e_2, s \rangle}
\end{align*}

\subsubsection{Inizializzazione della memoria}
Possibili varianti a livello di inizializzazione della memoria potrebbero essere: \begin{itemize}
	\item inizializzare implicitamente tutte le locazioni a 0;
	\item permettere assegnamenti ad una locazione $l$ tale che $l \notin dom(s)$ per inizializzare quella locazione.
\end{itemize}

\subsubsection{Valori memorizzabili}
Altre estensioni relative alla memoria (qui definita staticamente, ovvero l'insieme delle locazioni possibili è fisso) possono includere: \begin{itemize}
	\item la possibilità di memorizzare anche altri tipi di dato (non solo interi come in questo caso);
	\item la possibilità di avere una memoria definita dinamicamente, quindi dare la possiblità di avere sempre nuove locazioni disponibili oltre a quelle già in uso.
\end{itemize}

\subsection{Type systems}
Un type system è una struttura i cui usi principali sono: \begin{itemize}
	\item descrivere quando i programmi sono sensati;
	\item prevenire certi tipi di errore;
	\item strutturare i programmi;
	\item dare delle linee guida per la progettazione del linguaggio;
	\item dare informazioni utili per la fase di ottimizzazione da parte del compilatore;
	\item rinforzare alcune proprietà di \emph{sicurezza} del programma.
\end{itemize}

Definiamo la funzione \[ \Gamma \vdash e : T \]
che sostanzialmente assegna il tipo $T$ all'espressione $e$, per qualche tipo $T$ del linguaggio.

Aggiungiamo al linguaggio i tipi delle espressioni $T$ e i tipi delle locazioni $T_{loc}$:
\begin{align*}
	T ::=\ & int\ \vert\ bool\ \vert\ unit \\
	T_{loc} ::=\ & intref
\end{align*}

\subsubsection{Regole di tipaggio}
\begin{align*}
	&\inference[(int)]{-}{\type n : int}\ \text{per } n \in \mathbb{Z}  &\inference[(bool)]{-}{\type b : bool}\ \text{per } b \in \lbrace true, false \rbrace \\
	& & \\
	&\inference[(op+)]{\type e_1 : int \quad \type e_2:int}{\type e_1 + e_2 : int} &\inference[(op-geq)]{\type e_1 : int \quad \type e_2:int}{\type e_1 \geq e_2 : bool} \\
	&&\\
	&\inference[(if)]{\type e_1:bool \quad \type e_2:T \quad \type e_3:T}{\type \text{if } e_1 \text{ then } e_2 \text{ else } e_3:T} &\inference[(assign)]{\type e:int}{\type l:=e:unit}\ \text{se } \Gamma(l) = intref \\
	&& \\
	&\inference[(deref)]{-}{\type !l:int}\ \text{se } \Gamma(l) = intref &\inference[(skip)]{-}{\type skip:unit} \\
	&& \\
	&\inference[(seq)]{\type e_1:unit \quad \type e_2:T}{\type e_1;e_2:T} &\inference[(while)]{\type e_1:bool \quad \type e_2:unit}{\type \text{while } e_1 \text{ do } e_2:unit}
	&& \\
\end{align*}
\textbf{Nota:} le regole di tipaggio sono \textit{syntax-directed}, ovvero per ogni regola della sintassi astratta si ha una regola di tipaggio.

\subsubsection{Proprietà di tipaggio}
\begin{thm}[Progress]
	Se $\type e:T$ e $dom(\Gamma) \subseteq dom(s)$ allora $e$ è un valore oppure esiste una coppia $\langle e',s' \rangle$ tale che \[ \langle e,s \rangle \rightarrowtriangle \langle e',s' \rangle \]
\end{thm}

\begin{thm}[Type preservation]
	Se $\type e:T$ e $dom(\Gamma) \subseteq dom(s)$ e $\langle e,s \rangle \rightarrowtriangle \langle e',s' \rangle$ allora si ha che $ \type e':T$ e $dom(\Gamma) \subseteq dom(s') $
\end{thm}

Mettendo insieme le due proprietà sopra, si ottiene una nuova proprietà, esplicativa del fatto che programmi ben tipati non vanno mai in deadlock.

\begin{thm}[Safety]
	Se $\type e:T$, $dom(\Gamma) \subseteq dom(s)$ e $\langle e,s \rangle \rightarrowtriangle^\ast \langle e',s' \rangle$ allora $e'$ è un valore oppure esiste una coppia $\langle e'', s'' \rangle$ tale che $\langle e',s' \rangle \rightarrowtriangle \langle e'',s'' \rangle$
\end{thm}

\begin{thm}[Type inference]
	Dati $\Gamma$, $e$, può essere trovato il tipo $T$ tale che $\type e:T$ oppure può essere provato che $T$ non esiste.
\end{thm}

\begin{thm}[Decidibilità del type-checking]
	Dati $\Gamma$, $e$, $T$, è decidibile $\type e:T$
\end{thm}

\begin{thm}[Unicità del tipaggio]
	Se vale che $\type e:T$ e $\type e:T'$ allora $T=T'$.
\end{thm}

\newpage
\section{Forme di induzione}
L'induzione è una tecnica formale che consente di provare delle proprietà su determinate categorie di oggetti, sfruttando la natura di questi oggetti.
Esistono 3 tipi di induzione:
\begin{itemize}
	\item matematica;
	\item strutturale;
	\item rule induction\footnote{Appena avrò una traduzione valida la metterò.}.
\end{itemize}

\subsection{Induzione matematica}
È la forma di induzione più semplice, consiste infatti nel dimostrare una proprietà $P(-)$ su numeri naturali procedendo nel modo seguente:
\begin{enumerate}
\item \textbf{Caso base:} provare che $P(0)$ è vera, usando qualche procedimento matematico;
\item \textbf{Caso induttivo:}\begin{enumerate}
	\item assumere che l'ipotesi induttiva valga, ovvero che valga $P(k)$;
	\item dall'ipotesi induttiva dimmostrare che vale $P(k+1)$, usando qualche procedimento matematico.
\end{enumerate}
\end{enumerate}
Se i punti precedenti sono veri, allora $P(n)$ è vera per ogni numero naturale.

\subsection{Induzione strutturale}
\subsubsection{Induzione strutturale su numeri naturali}
Per dimostrare una proprietà $P$ su numeri naturali basta applicare il seguente metodo: \begin{itemize}
	\item \textbf{Caso base:} dimostrare che vale $P(0)$;
	\item \textbf{Caso induttivo:} dimostrare che è vera $P(succ(K))$ assumendo come ipotesi induttiva che valga $P(K)$ per qualche $K \in \mathbb{N}$.
\end{itemize}

L'induzione strutturale consiste quindi nell'assumere che l'ipotesi induttiva valga per la \textit{sottostruttura} di $succ(K)$.

\subsubsection{Induzione strutturale su strutture complesse}
Prendiamo come esempio la costruzione di alberi binari. Diamo la seguente grammatica per costruire gli alberi: \[ T::= leaf\ |\ tree(T,T) \]

In tal caso partiamo col presupposto che: \begin{itemize}
		\item \textbf{Caso base:} una foglia sia un albero binario;
		\item \textbf{Caso induttivo:} se $L$ e $R$ sono alberi binari, allora lo è anche $tree(L,R)$.
\end{itemize}

\subsection{Rule induction}
L'idea di base della rule induction consiste nell'ignorare la struttura di ciò che si deriva per fare induzione sulla dimensione dell'albero di derivazione.

Per provare formalmente una proprietà $P(D)$ su una derivazione $D$, si procede come segue: \begin{enumerate}
	\item \textbf{Caso base:} dimostrare che $P(A)$ è vera, per ogni assioma $A$;
	\item \textbf{Caso induttivo:} per ogni regola della forma \[ \inference[(regola)]{h_1\ h_2\ ...\ h_n}{c} \] si dimostra che ogni derivazione che termina con l'utilizzo di questa regola soddisfa la proprietà. Questa derivazione ha sottoderivazioni $D_1, D_2,...,D_n$ che terminano con le ipotesi $h_1, h_2,...,h_n$. Per ipotesi induttiva si assume che valga $P(D_i)$ con $1\leq i \leq n$.
	
\end{enumerate}
\newpage
\section{Aspetti funzionali}
Estendiamo la sintassi data in \ref{imp} con:	 \begin{align*}
	\text{Variabili } &x \in \mathbb{X}, \text{con } x = \lbrace x,y,z,...\rbrace \\
	\text{Espressioni }&e::=\ ...\ |\ \text{fn }x:T \Rightarrow e\ |\ ee\ |\ x
\end{align*}
e i tipi con: \begin{align*}
	T\ ::=\ ...\ |\ T \to T
\end{align*}

Assumiamo che: \begin{itemize}
	\item l'applicazione di funzioni $ee$ è associativa a sinistra;
	\item i tipi delle funzioni sono associativi a destra;
	\item il corpo di $fn$ si estende a sinistra quanto più è possibile;
	\item $fn\ x:unit \Rightarrow fn\ y:int \Rightarrow x;y$ è di tipo $unit \to int \to int$.
\end{itemize}

\subsection{Variabili free e bound}
Intuitivamente, diciamo che una variabile è \textit{free} in $e$ se $x$ non occorre in nessun termine della forma \lstinline|fn x:T| $\Rightarrow$ ...

Più formalmente definiamo le variabili free come una funzione: \[ fv(): Exp \to 2^\mathbb{X} \] dove $\mathbb{X}$ è l'insieme delle variabili. La funzione $fv$ è definita come: \begin{align*}
	fv(x) &\triangleq \lbrace x \rbrace \\
	fv(\code{fn x:T} \Rightarrow e) &\triangleq fv(e) \setminus \lbrace x \rbrace \\
	fv(e_1 e_2)= fv (e_1;e_2) &\triangleq fv(e_1) \cup fv(e_2) \\
	fv(n)=fv(b)=fv(!l)=fv(\code{skip}) &\triangleq \emptyset \\
	fv(e_1 \code{op} e_2) = fv(\ \code{while}\ e_1\ \code{do}\ e_2) &\triangleq fv(e_1) \cup fv(e_2) \\
	fv(l \code{:=} e) &\triangleq fv(e) \\
	fv(\code{if}\ e_1\ \code{then}\ e_2\ \code{else}\ e_3) &\triangleq fv(e_1) \cup fv(e_2) \cup fv(e_3)
\end{align*}

\begin{definit}
	Un'espressione $e$ si dice \textbf{chiusa} se $fv(e) = \emptyset$.
\end{definit}

\subsection{Alpha conversion}
Nell'espressione \lstinline|fn x : T| $\Rightarrow e$ la variabile $x$ è \textit{bound} in $e$. Diciamo che: \begin{itemize}
	\item $x$ è il parametro formale della funzione, quindi ogni occorrenza di $x$ che non è in una funzione annidata alla funzione attuale indica la stessa cosa;
	\item al di fuori della definizione della funzione, la variabile $x$ non ha significato;
\end{itemize}

Basandoci su quanto detto nei due punti precedenti, possiamo concludere che il nome del parametro formale nella funzione \textbf{non modifica} il comportamento della funzione. Assumiamo quindi di poter \textit{rimpiazzare il vincolo su $x$ e tutte le occorrenze di $x$ in una certa espressione $e$ con una variabile \textbf{fresh} che non occorra da nessun'altra parte}.

\subsection{Sostituzioni}
\subsubsection{Sostituzioni singole}
Un perno della semantica delle funzioni è dato dalle sostituzioni, ovvero il rimpiazzo a runtime di un parametro attuale con un parametro formale. Una sostituzione è indicata con \[ \subs{e_2}{e_1}{x}  \] e indica la sostituzione di $x$  con $e_2$ nell'espressione $e_1$, per tutte le occorrenze libere di $x$. Le sostituzioni funzionano come segue: \begin{align*}
	\subs{n}{e}{x} &\triangleq n \\
	\subs{b}{e}{x} &\triangleq b \\
	\subs{\code{skip}}{e}{x} &\triangleq \code{skip} \\
	\subs{x}{e}{x} &\triangleq e \\
	\subs{y}{e}{x} &\triangleq y \\
	\subs{\code{(fn x:T} \Rightarrow e_1 \code{)}}{e}{z} &\triangleq \code{(fn x:T} \Rightarrow \subs{e_1}{e}{z}\code{)} \text{se } x \notin fv(e) \\
	\subs{\code{(fn x:T} \Rightarrow e_1 \code{)}}{e}{z} &\triangleq \code{(fn x:T} \Rightarrow (\subs{e_1}{e}{z})\lbrace \sfrac{e}{z} \rbrace \code{)} \text{se } x \in fv(e) \wedge y \text{ è fresh}\footnotemark \\
	\subs{\code{(fn x:T} \Rightarrow e_1 \code{)}}{e}{x} &\triangleq \code{(fn x:T} \Rightarrow e_1 \code{)} \\
	\subs{\code{(e}_1; \code{e}_2 \code{)}}{e}{x} &\triangleq (\subs{e_1}{e}{x}\subs{e_2}{e}{x})
\end{align*}
\footnotetext{Operando con alpha-conversion.}
Le altre espressioni dopo una sostituzione rimangono invariate per il semplice motivo che non sono funzioni, quindi non va sostituito alcun parametro.

\subsubsection{Sostituzioni simultanee}
Le sostituzioni possono essere implementate in modo da poter essere anche simultanee, ovvero con lo scopo di poter sostituire più variabili contemporaneamente. In generale, una sostituzione simultanea è una funzione parziale $\sigma: \mathbb{X} \to Exp$.

Sintatticamente viene indicato con $e \sigma$ l'espressione risultante dalla sostituzione simultanea di ogni $x \in dom(\sigma)$ con la corrispondente espressione $\sigma(x)$. La sostituzione dei parametri viene indicata con \[ \lbrace \sfrac{e_1}{x_1}, ..., \sfrac{e_k}{x_k} \rbrace \]

\subsection{Lambda calcolo}
Il lambda calcolo è un linguaggio dove: \begin{itemize}
	\item ogni termine è una funzione;
	\item ogni termine può essere applicato ad un altro termine;
	\item le funzioni del linguaggio \lstinline|fn x:T| $\Rightarrow e$ diventano funzioni del tipo $\lambda x:T.e$.
\end{itemize}

La sintassi del lambda-calcolo non tipato è: \[ M \in Lambda ::=\ x\ |\ \lambda x.M\ |\ MM \]

\subsection{Applicazione di funzioni}
Intuitivamente, nell'espressione $M_1M_2$, per applicare $M_2$ a $M_1$ si procede prima risolvendo $M_1$ ad un termine del tipo $\lambda x.M$, poi si procede in base a una delle strategie di valutazione possibili: \begin{itemize}
\item \textit{call-by-value:} si valuta $M_2$ ad un valore $v$, poi si valuta $\subs{M}{v}{x}$;
\item \textit{call-by-name:} si valuta direttamente $\subs{M}{M_2}{x}$.
\end{itemize}

\subsubsection{Semantica dell'applicazione di funzioni}
Estendiamo l'insieme dei valori con 
\[ 
	\text{Values } v::= b\ |\ n\ |\ skip\ |\ fn\ x:T \Rightarrow e 
\]
La semantica funziona come di seguito:
\[ \inference[App]{M_1 \rightarrowtriangle M_1'}{M_1M_2 \rightarrowtriangle M_1'M_2} \]
Inoltre, in modalità call-by-value: \begin{adjustwidth}{-1.3cm}{}
\begin{align*}
	\inference[CBV-app1]{\langle e_1, s \rangle \rightarrowtriangle \langle e_1', s' \rangle}{\langle e_1e_2,s \rangle \rightarrowtriangle \langle e_1'e_2, s' \rangle}\quad  \inference[CBV-app2]{\langle e_2,s \rangle \rightarrowtriangle \langle e_2',s' \rangle}{\langle ve_2,s \rangle \rightarrowtriangle \langle ve_2',s' \rangle} \quad
	\inference[CBV-fn]{-}{\langle (\text{fn }x:T \Rightarrow e)v, s \rangle \rightarrowtriangle \langle \subs{e}{v}{x},s \rangle}
\end{align*}
\end{adjustwidth}
mentre in modalità call-by-name: 
\begin{align*}
	\inference[CBN-app]{\langle e_1, s \rangle \rightarrowtriangle \langle e_1', s' \rangle}{\langle e_1e_2,s \rangle \rightarrowtriangle \langle e_1'e_2, s' \rangle} \quad \inference[CBN-fn]{-}{\langle (\text{fn }x:T \Rightarrow e)e_2, s \rangle \rightarrowtriangle \langle \subs{e}{e_2}{x},s \rangle}
\end{align*}

Introduciamo inoltre una nuova semantica che raccoglie le due precedenti: 
\begin{align*}
	\inference[BETA-app1]{\langle e_1, s \rangle \rightarrowtriangle \langle e_1', s' \rangle}{\langle e_1e_2,s \rangle \rightarrowtriangle \langle e_1'e_2, s' \rangle} \quad &\inference[BETA-app2]{\langle e_2,s \rangle \rightarrowtriangle \langle e_2',s' \rangle}{\langle e_1e_2,s \rangle \rightarrowtriangle \langle e_1e_2',s' \rangle} \\ \\
	\inference[BETA-fn1]{-}{\langle (\text{fn }x:T \Rightarrow e)e_2, s \rangle \rightarrowtriangle \langle \subs{e}{e_2}{x},s \rangle} \quad &\inference[BETA-fn2]{-}{\langle \text{fn }x:T \Rightarrow e, s \rangle \rightarrowtriangle \langle \text{fn }x:T \Rightarrow e', s \rangle}
\end{align*}

\subsection{Tipaggio di funzioni}
Estendiamo l'insieme dei tipi come segue: 
\[ 
	TypeEnv = \mathbb{L} \cup \mathbb{X} \rightharpoonup T_{loc} \cup T 
\] 
tale che: 
\begin{itemize}
	\item $\forall l \in dom(\Gamma). \Gamma(l) \in T_{loc}$
	\item $\forall x \in dim(\Gamma). \Gamma(x) \in T$
\end{itemize}

Definiamo le regole di tipaggio: 
\begin{align*}
	\inference[var]{-}{\type x:T} \text{se } \Gamma(x) = T \quad 
	\inference[fn]{\Gamma, x :T \vdash e:T'}{\type \text{fn } x :T \Rightarrow e:T \to T'} \quad
	\inference[app]{\type e_1:T \to T' \quad \type e_2:T}{\type e_1e_2:T'}
\end{align*}

Qui di seguito definiamo alcune proprietà del tipaggio:
\begin{thm}[Progress]
	Se $e$ è chiusa, $\type e:T$ e $dom(\Gamma) \subseteq dom(s)$ allora $e$ è un valore oppure esiste una configurazione $\langle e',s' \rangle$ tale $\langle e,s \rangle \rightarrowtriangle \langle e',s' \rangle$.
\end{thm}

\begin{thm}[Type preservation]
	Se $e$ è chiusa, $\type e:T$, $dom(\Gamma) \subseteq dom(s)$ e $\langle e,s \rangle \rightarrowtriangle \langle e',s' \rangle$ allora vale che $\type e:T'$, $e'$ è chiusa e $dom(\Gamma) \in dom(s')$.
\end{thm}

\begin{thm}[Normalization]
	Nei sottolinguaggi senza cicli while o operazioni sulla memoria, se vale che $\type e:T$ e $e$ è chiusa, allora esiste un valore $v$ tale che, per ogni memoria $s$, \[ \langle e,s \rangle \rightarrowtriangle^\ast \langle v,s \rangle \]
\end{thm}

\subsection{Dichiarazioni locali}
Le dichiarazioni locali sono usate per aumentare la leggibilità del codice e consistono nel nominare una certa espressione restringendo al contempo il suo scope. Il costrutto da introdurre è \lstinline|let |$y:$\lstinline|int| $=1+2$ \lstinline| in |  $y \geq y+4$

La valutazione procede alla maniera seguente:
\begin{itemize}
	\item si valuta $1+2$ a $3$;
	\item si valuta $y \geq y+4$ sostituendo a $y$ il valore $3$;
\end{itemize}

Estendiamo la sintassi con 
\[ 
	e::=\ \dots |\ \text{let } x:T = e_1\text{ in } e_2  
\] 
e diamo la relativa regola di tipaggio 
\[ 
	\inference[(let)]{\type e_1:T \quad \Gamma,x:T \vdash e_2:T'}{\type let\ x:T = e_1\ in\ e_2:T'} 
\]

Dal momento che $x$ è una variabile locale, $\Gamma$ non contiene una entry per $x$, quindi potrebbe essere necessario ricorrere ad alpha-conversion.

\subsubsection{Dichiarazioni locali e alpha conversion}
Analogamente a quanto detto in precedenza, l'alpha-conversion è applicabile anche al costrutto \lstinline|let|.
In sostanza, si opera come segue: \[ (\code{let}\ x:T = e_1\ \code{in}\ e_2) =_\alpha \code{let}\ y:T = e_1\ \code{in}\ \subs{e_2}{y}{x} \]

dove $y$ è una fresh variable, ovvero non si trova nè in $e_1$, nè in $e_2$.

\subsubsection{Dichiarazioni locali, free variables e sostituzioni}
Definiamo le variabili libere per il costrutto \lstinline|let| come \[ fv(\code{let}\ x:T = e_1\ \code{in}\ e_2)  = fv(e_1) \cup (fv(e_2) \setminus \lbrace x \rbrace) \]
e le sostituzioni nel seguente modo: \begin{align*}
	\subs{(\code{let}\ x:T = e_1\ \code{in}\ e_2)}{e}{z} &= (\code{let}\ x:T = \subs{e_1}{e}{z}\ \code{in}\ \subs{e_2}{e}{z}) &\text{if } x \notin fv(e) \\
	 \subs{(\code{let}\ x:T = e_1\ \code{in}\ e_2)}{e}{z} &= (\code{let}\ x:T = \subs{e_1}{e}{z}\ \code{in}\ (\subs{e_2}{y}{x}) \lbrace \sfrac{e}{z} \rbrace) &\text{if } x \in fv(e) \wedge y \text{fresh} \\
	 \subs{(\code{let}\ x:T = e_1\ \code{in}\ e_2)}{e}{x} &= (\code{let}\ x:T = \subs{e_1}{e}{x}\ \code{in}\ e_2) &
\end{align*}

\subsubsection{Semantica small-step per dichiarazioni locali}

La semantica del costrutto \lstinline|let| funziona in modi differenti a seconda del tipo di chiamata. In modalità call-by-value \begin{align*}
	&\inference[(CBV-let1)]{\langle e_1, s \rangle \rightarrowtriangle \langle e_1', s' \rangle}{\langle \code{let}\ x:T = e_1\ \code{in}\ e_2,s \rangle \rightarrowtriangle \langle \code{let}\ x:T = e_1'\ \code{in}\ e_2, s' \rangle} \\ \\
	&\inference[(CBV-let2)]{-}{\langle \code{let}\ x:T = v\ \code{in}\ e_2,s \rangle \rightarrowtriangle \langle \subs{e_2}{v}{x}, s \rangle}
\end{align*}
mentre in modalità call-by-name: \[ \inference[(CBN-let)]{-}{\langle \code{let}\ x:T = e_1\ \code{in}\ e_2, s \rangle \rightarrowtriangle \langle \subs{e_2}{e_1}{x}, s \rangle} \]

In realtà il costrutto \lstinline|let| funge semplicemente da espansione sintattica, nel senso che ciò che si esprime con il costrutto \lstinline|let| può tranquillamente essere implementato con altri costrutti, ad esempio: 	
\[
  (fn\ x:\text{unit} \Rightarrow e_2) e_1 \equiv \code{let}\ x:\text{unit} = e_1\ \code{in}\ e_2 \equiv e_1; e_2
\]

\subsection{Ricorsione}
La ricorsione è implementata tramite punti fissi\footnotemark. \footnotetext{Un punto fisso $x$ per un operatore $f$ è tale se vale che $f(x) = x$.} Estendiamo il linguaggio con il costrutto $fix$: \[ e::= \dots\ |\ fix.e \]
La regola per il tipaggio di $fix$ è la seguente: 
\[ 
	\inference[(T-fix)]{\type e: (T_1 \to T_2) \to (T_1 \to T_2)}{\type fix.e:T_1 \to T_2} 
\]


La semantica in sè è relativamente semplice: 
\begin{align*}
	&\inference[(Fix-cbn)]{-}{fix.e \rightarrowtriangle e(fix.e)} \\ \\
	&\inference[(Fix-cbv)]{e \equiv fn\ f: T_1 \to T_2 = e_1 \Rightarrow e_2}{fix.e \rightarrowtriangle e(fn\ x :T_1 \Rightarrow fix.e\ x)}
\end{align*}

\newpage
\section{Dati e memoria variabile}

Fino ad ora abbiamo lavorato solo su tipi di dato semplici, quali interi, booleani, unit e funzioni. Ora procediamo introducendo dati strutturati, e modificando la concezione di memoria mutabile che abbiamo usato fino ad ora. 

Introduciamo quindi il prodotto tra tipi $T_1 * T_2$, che consente di lavorare su \textit{tuple}, e la somma di tipi $T_1 + T_2$, che rappresenta l'unione disgiunta, con il valore risultante di tipo $T_1$ \textit{oppure} di tipo $T_2$.

\subsection{Somme e moltiplicazioni tra tipi}
Estendiamo il linguaggio utilizzato fino ad ora con: \begin{align*}
	e &::= \dots\ |\ (e_1,e_2)\ |\ \sharp1\ e\ |\ \sharp2\ e\ \\
	T &::= \dots\ |\ T_1 * T_2 \\
	v &::= \dots\ |\ (v_1, v_2)
\end{align*}

\textbf{Nota:} le tuple sono ordinate, non sono arbitrarie.
Inoltre sono state aggiunte delle proiezioni ($\sharp$), che estraggono elementi dai record.

\paragraph{Moltiplicazioni.}
La semantica dei costrutti di moltiplicazione appena introdotti funziona come segue: \begin{align*}
	&\inference[(pair1)]{\langle e_1,s \rangle \goesto \langle e_1',s' \rangle}{\langle (e_1, e_2),s \rangle \goesto \langle (e_1', e_2), s' \rangle} \quad &\inference[(pair2)]{\langle e_2,s \rangle \goesto \langle e_2',s' \rangle}{\langle (v, e_2),s \rangle \goesto \langle (v, e_2'), s' \rangle} \\
	&\inference[(proj1)]{-}{\langle \sharp 1 (v_1, v_2),s \rangle \goesto \langle v_1, s \rangle} \quad &\inference[(proj2)]{-}{\langle \sharp 2 (v_1, v_2),s \rangle \goesto \langle v_2, s \rangle} \\
	&\inference[(proj3)]{\langle e,s \rangle \goesto \langle e',s' \rangle}{\langle \sharp 1\ e, s \rangle \goesto \langle \sharp 1\ e', s \rangle} \quad &\inference[(proj4)]{\langle e,s \rangle \goesto \langle e',s' \rangle}{\langle \sharp 2\ e, s \rangle \goesto \langle \sharp 2\ e', s \rangle}
\end{align*}

Il tipaggio invece procede come segue: 
\[
	\inference[(pair)]{\type e_1:T_1 \quad \type e_2:T_2}{\type (e_1, e_2): T_1 * T_2} \quad \inference[(proj1)]{\type e:T_1*T_2}{\type \sharp 1\ e:T_1} \] \[ \inference[(proj2)]{\type e:T_1*T_2}{\type \sharp 2\ e:T_2} 
\]

\paragraph{Somme.}
Per quanto riguarda la somma di tipi, l'estensione da eseguire è la seguente: \begin{align*}
	e ::= \dots\ &|\ \text{inl } e:T\ |\ \text{inr } e:T\\ &|\ (\text{case } e \text{ of inl }(x_1:T_1) \Rightarrow e_1\ |\ \text{inr } (x_2:T_2) \Rightarrow e_2) \\
	T ::= \dots\ &|\ T_1 + T_2 \\
	v ::= \dots &|\ \text{inl }v:T\ |\ \text{inr }v:T
\end{align*}

La semantica delle somme di tipi è definita come segue: \begin{align*}
	\inference[(inl)]{\langle e,s \rangle \goesto \langle e',s' \rangle}{\langle \text{inl }e:T,s \rangle \goesto \langle \text{inl } e':T, s' \rangle} \quad \inference[(inr)]{\langle e,s \rangle \goesto \langle e',s' \rangle}{\langle \text{inr }e:T,s \rangle \goesto \langle \text{inr } e':T, s' \rangle}
\end{align*}
\begin{adjustwidth}{-1.7cm}{}
	\begin{align*}
	\inference[(case1)]{\langle e,s \rangle \goesto \langle e',s' \rangle}{\langle \text{case } e \text{ of inl }(x_1:T_1) \Rightarrow e_1\ |\ \text{inr } (x_2:T_2) \Rightarrow e_2, s \rangle \goesto \langle \text{case } e' \text{ of inl }(x_1:T_1) \Rightarrow e_1\ |\ \text{inr } (x_2:T_2) \Rightarrow e_2, s' \rangle}
	\end{align*}
\end{adjustwidth}
\newpage
\begin{align*}
	&\inference[(case2)]{-}{\langle \text{case inl } v:T \text{ of inl }(x_1:T_1) \Rightarrow e_1\ |\ \text{inr } (x_2:T_2) \Rightarrow e_2, s \rangle \goesto \langle \subs{e_1}{v}{x_1},s \rangle} \\ \\
	&\inference[(case3)]{-}{\langle \text{case inr } v:T \text{ of inl }(x_1:T_1) \Rightarrow e_1\ |\ \text{inr } (x_2:T_2) \Rightarrow e_2, s \rangle \goesto \langle \subs{e_2}{v}{x_2},s \rangle} \\
\end{align*}

Il tipaggio delle somme procede nel seguente modo: 
\[
	\inference[(inl)]{\type e:T_1}{\type (\text{inl } e:T_1+T_2):T_1+T_2} \quad \inference[(inr)]{\type e:T_2}{\type (\text{inr } e:T_1+T_2):T_1+T_2} 
\]
\\
\[
	\inference[(case)]{\type e:T_1+T_2 \quad \Gamma, x_1: T_1 \vdash e_1:T \quad \Gamma, x_2: T_2 \vdash e_2:T}{\type (\text{case } e \text{ of inl }(x_1:T_1) \Rightarrow e_1\ |\ \text{inr } (x_2:T_2) \Rightarrow e_2):T}
\]

\subsection{Record}
I record costituiscono una generalizzazione del prodotto tra tipi, che viene esteso fino a generare una tupla di lunghezza arbitraria.

Un record è quindi una struttura del tipo:
\begin{align*}
	e &::=\ \dots\ |\ \lbrace lab_1=e_1, \dots, lab_n = e_n \rbrace\ |\ \sharp lab\ e \\
	T &::=\ \dots\ |\ \lbrace lab_1:T_1, \dots, lab_n:T_n \rbrace \\
	v &::=\ \dots\ |\ \lbrace lab_1=v_1, \dots, lab_n = v_n \rbrace
\end{align*}

\textbf{Nota:} in ogni record un'etichetta non occorre mai più si una volta.

La semantica dei record è abbastanza semplice:
\begin{adjustwidth}{-1.3cm}{}
	\begin{align*}
	&\inference[(record1)]{\langle e_i, s \rangle \goesto \langle e_i',s' \rangle}{\langle \lbrace lab_1=v_1, \dots, lab_i = e_i, \dots, lab_k = e_k \rbrace, s \rangle \goesto \langle \lbrace lab_1=v_1, \dots, lab_i = e_i', \dots, lab_k = e_k \rbrace, s' \rangle} \\ \\
	&\inference[(record2)]{-}{\langle \sharp lab_i \lbrace lab_1=e_1. \dots, lab_i=e_i, \dots, lab_k=e_k \rbrace, s \rangle \goesto \langle v_i, s \rangle} \qquad \inference[(record3)]{\langle e,s \rangle \goesto \langle e',s' \rangle}{\langle \sharp lab\ e,s \rangle \goesto \langle \sharp lab\ e',s' \rangle}
	\end{align*}
\end{adjustwidth}

Il tipaggio dei record invece: \begin{align*}
	&\inference[(record)]{\type e_1:T_1 \quad \dots \quad \type e_k:T_k}{\type \lbrace lab_1=e_1, \dots, lab_k=e_k \rbrace : \lbrace lab_1:T_1, \dots, lab_k:T_k \rbrace} \\ \\
	&\inference[(recordproj)]{\type e: \lbrace lab_1:T_1, \dots, lab_k:T_k \rbrace}{\type \sharp lab_i\ e:T_i}
\end{align*}

\subsection{Memoria dinamica}
I linguaggi moderni possiedono un concetto di memoria dinamica che supera i problemi che ci sono nella memoria del nostro linguaggio fino ad ora, ovvero: \begin{itemize}
	\item si possono salvare solo valori interi;
	\item non si possono creare nuove locazioni;
	\item non si possono scrivere funzioni che astraggano sulle locazioni di memoria, come ad esempio $fn\ l:intref \Rightarrow\ !l$.
\end{itemize}

Per rimuovere queste limitazioni, modifichiamo la sintassi come segue\footnotemark: \begin{align*}
	e &::=\ \dots\ |\ \cancel{l:=e}\ |\ \cancel{!l}\ |\ e_1:=e_2\ |\ !e\ |\ ref\ e\ |\ l \\
	T &::=\ \dots\ |\ ref\ T \\
	T_{loc} &::=\ \cancel{intref}\ |\ ref\ T \\
	v &::=\ \dots\ |\ l
\end{align*}
\footnotetext{Le espressioni barrate sono \textbf{rimosse} dal linguaggio.}
Aggiorniamo la funzione di $Store$ ridefinendola come segue: \[ s: \mathbb{L} \rightharpoonup \mathbb{V} \]

La semantica dei costrutti appena introdotti è le seguente: \begin{align*}
	&\inference[(ref1)]{-}{\langle \text{ref } v,s \rangle \goesto \langle l, s\left[ l \mapsto v \right] \rangle}\ l \notin dom(s) \quad \inference[(ref2)]{\langle e,s \rangle \goesto \langle e',s' \rangle}{\langle \text{ref } e,s \rangle \goesto \langle \text{ref }e',s' \rangle} \\ \\
	&\inference[(deref1)]{-}{\langle !l, s \rangle \goesto \langle v,s \rangle}\ \text{if } l \in dom(s) \text{ and } s(l)=v \quad \inference[(deref2)]{\langle e,s \rangle \goesto \langle e',s' \rangle}{\langle !e,s \rangle \goesto \langle !e',s' \rangle} \\ \\
	&\inference[(assign1)]{-}{\langle l:= v,s \rangle \goesto \langle \text{skip}, s \lbrack l \mapsto v \rbrack \rangle}\ \text{if } l \in dom(s) \quad \inference[(assign2)]{\langle e,s \rangle \goesto \langle e',s' \rangle}{\langle l:=e,s \rangle \goesto \langle l:=e',s' \rangle}
\end{align*}
\[
	\inference[(assign3)]{\langle e_1,s \rangle \goesto \langle e_1',s' \rangle}{\langle e_1:=e_2,s \rangle \goesto \langle e_1':=e_2,s' \rangle}
\]

Le corrispondenti regole di tipaggio sono: \begin{align*}
	&\inference[(ref)]{\type e:T}{\type \text{ref } e: \text{ref }T} \quad \inference[(assign)]{\type e_1:\text{ref } T \quad \type e_2:T}{\type (e_1:=e_2):unit} \\ \\
	&\inference[(deref)]{\type e:\text{ref } T}{\type !e:T} \quad \inference[(loc)]{-}{\type l:\text{ref }T}\ \Gamma(l)=\text{ref }T
\end{align*}

Le principali novità sono le seguenti: \begin{itemize}
	\item l'espressione $\text{ref } v$ ora ritorna una nuova locazione di memoria;
	\item all'inizio un programma non ha locazioni già disponibili, sono create a runtime;
	\item è possibile il costrutto $\text{ref}(\text{ref}(3))$;
	\item la determinatezza non è più valida, in quanto le locazioni di memoria sono decise in maniera arbitraria;
	\item la memoria cresce sempre più durante l'esecuzione (si rende necessario un \textit{garbage collector}).
\end{itemize}

\subsection{Aggiornamento delle proprietà del tipaggio}
\begin{thm}[Memoria ben tipata]
	Scriviamo che $\Gamma \vdash s$ se: \begin{itemize}
		\item $dom(\Gamma) = dom(s)$;
		\item $\forall l \in dom(s)$, se $\Gamma(l)=\text{ref }T$ allora $\Gamma \vdash s(l):T$.
	\end{itemize}
\end{thm}

\begin{thm}[Progress]
	Se $e$ è chiusa, inoltre valgono $\type e:T$ e $\type s$ allora $e$ è un valore oppure esistono $e',s'$ tali che $\langle e,s \rangle \goesto \langle e',s' \rangle$.
\end{thm}

\begin{thm}[Type preservation]
	Se $e$ è chiusa, $\type e:T$, $\type s$ e $\langle e,s \rangle \goesto \langle e',s' \rangle$ allora $e'$ è chiusa e, per qualche $\Gamma'$ con dominio disgiunto da $\Gamma$ si ha che $\Gamma, \Gamma' \vdash e':T$ e $\Gamma, \Gamma' \vdash s$.
\end{thm}

\newpage
\section{Sotto-tipaggio}
La motivazione principale per la creazione del sotto tipaggio è sostanzialmente il fatto di non poter tipare (con i type systems visti fino ad ora) i programmi che, aspettandosi un certo argomento, ricevono come parametro un argomento più ricco dal punto di vista strutturale. Ad esempio, se una certa funzione si aspetta un argomento 
\[
	\lbrace left: \text{int} \rbrace
\]
le si può passare tranquillamente un argomento del tipo \[ \lbrace left:\text{int}, right:\text{int} \rbrace \] senza avere problemi nell'accesso alla struttura dati in quanto un campo con la label $left$ si trova in entrambi i parametri.

Introduciamo quindi una regola di sussunzione, ovvero:
\[
	\inference[(sub)]{\type e:T \quad T<:T'}{\type e:T'}
\]

Nella regola di sussunzione, $T$ è sottotipo di $T'$, quindi \textbf{un oggetto di tipo $T$ può sempre essere usato dovunque ci si aspetti un oggetto di tipo $T'$}.

La relazione di sottotipaggio è \textbf{riflessiva} e \textbf{transitiva}.

Le principali modifiche apportate dal subtyping si riflettono sul tipaggio dei programmi: vengono infatte mantenute le proprietà di type-preservation e progress, ma le regole di tipaggio non sono più syntax-directed.

\subsection{Sottotipaggio sui record}
Con il sottotipaggio si può esprimere il riordinamento dei campi dei record, il passaggio di record più grandi come parametro oppure il sottotipaggio dei singoli campi di uno stesso record:
\begin{align*}
		&\inference[(rec-perm)]{\pi \text{ permutazione di } 1,\dots,k}{\lbrace p_1:T_1, \dots, p_k:T_k \rbrace <: \lbrace p_{\pi (1)}:T_1, \dots, p_{\pi (k)}:T_k \rbrace } \\ \\
		&\inference[(rec-width)]{-}{\lbrace p_1:T_1, \dots, p_k:T_k,p_{k+1}:T_{k+1}, \dots, p_z:T_z \rbrace <: \lbrace p_1:T_1, \dots, p_k:T_k \rbrace } \\ \\
		&\inference[(rec-depth)]{T_1 <: T_1' \quad \dots \quad T_k<:T_k'}{\lbrace p_1:T_1, \dots, p_k:T_k \rbrace <: \lbrace p_1:T_1', \dots, p_k:T_k' \rbrace }
\end{align*} 

\subsection{Sottotipaggio su funzioni}
La regola di sottotipaggio su funzioni è la seguente: 
\[ 
	\inference[(fun-sub)]{T_1 >: T_1' \quad T_2 <: T_2'}{T_1 \to T_2 <: T_1' \to T_2'}
\]

Il sottotipaggio su funzioni è detto essere: \begin{itemize}
	\item \textit{covariante} sulla sinistra di $\to$;
	\item \textit{controvariante} in caso contrario.
\end{itemize}

\subsection{Sottotipaggio su somme e prodotti}
Il sottotipaggio è covariante sia sulla somme che sui prodotti: 
\begin{align*}
	\inference[(prod-sub)]{T_1<:T_1' \quad T_2<:T_2'}{T_1 \ast T_2 <: T_1' \ast T_2'} \quad
	\inference[(sum-sub)]{T_1 <:T_1' \quad T_2<:T_2'}{T_1 + T_2 <: T_1' + T_2'}
\end{align*}

\subsection{Downcasting}
La regola di sussunzione permette l'upcasting al momento: si possono passare argomenti "più ampi" al posto di quelli "più piccoli". Per il downcast, supponiamo di aggiungere alle espressioni la seguente:
\[
	e::=\ \dots\ |\ (T)e
\]
 e aggiungiamo la regola di tipaggio \[ \inference[(down-cast)]{\type e:T' \quad T<: T'}{\type (T)e:T } \]
 L'espressione $(T)e$ \textbf{non può essere tipata a tempo di compilazione}, ma solo a runtime, in quanto bisogna sapere il "vero tipo" di $e$. Ad esempio, avendo un down-cast come questo: \[ (\lbrace left:\text{int} \rbrace) !l\] non si saprà mai a compile-time il tipo ritornato da $!l$, ma lo si scoprirà solo a runtime. Notare che il tipo ritornato potrebbe anche non essere "castabile" a $\lbrace left:\text{int} \rbrace$.
\newpage

\section{Equivalenze semantiche}
Intuitivamente, diciamo che due programmi $P_1$ e $P_2$ sono semanticamente equivalenti ($P_1 \simeq P_2$) se uno dei due può essere rimpiazzato dall'altro, in un qualsiasi contesto.

Con una buona equivalenza semantica, si può quindi: \begin{itemize}
	\item comprendere cosa sia un programma;
	\item dimostrare alcune particolari proprietà (\textit{program verification});
	\item dimostrare che le ottimizzazioni di alcuni compilatori sono \textit{sound};
	\item comprendere le differenze semantiche tra due programmi.
\end{itemize}

In particolare per avere una buona relazione di equivalenza si deve avere che: \begin{enumerate}
	\item programmi che convergono a valori diversi, iniziando dalla stessa memoria, non devono essere equivalenti, quindi \[ (\exists s, s_1, s_2, v_1, v_2. \langle e_1, s \rangle \goesto^\ast \langle v_1, s_1 \rangle \wedge \langle e_2, s_2 \rangle \goesto^\ast \langle v_2, s_2 \rangle \wedge v_1 \neq v_2) \implies e_1 \nsimeq e_2 \]
	\item i programmi che terminano non devono essere simili ai programmi che non terminano;
	\item $\simeq$ deve essere una relazione di equivalenza;
	\item $\simeq$ deve essere una \textit{congruenza}, ovvero se vale che $e_1 \simeq e_2$ per un qualche contesto $C\left[ \cdot \right]$, allora deve valere che $C\left[e_1\right] \simeq C\left[e_2\right]$;
	\item $\simeq$ deve valere per quanti più programmi possibili.
\end{enumerate}

Un contesto $C\left[\cdot\right]$ è un programma non completo, ovvero un programma con una parte mancante, la quale deve essere istanziata con un qualche programma $P$. Inoltre, se vale che $\simeq$ è una congruenza, allora avendo che $P \simeq Q$ si ottiene che $C\left[P\right] \simeq C\left[Q\right]$.

Considerando il semplice linguaggio imperativo, diamo qualche definizione formale.

\begin{definit}[Trace equivalence]
	Definiamo che $e_1 \treq e_2$ vale se, $\forall s. dom(\Gamma) \subseteq dom(s)$, si ha che $\type e_1:T$, $\type e_2:T$ e \begin{itemize}
		\item $(\langle e_1, s \rangle \goesto^\ast \langle v, s' \rangle) \implies (\langle e_2, s \rangle \goesto^\ast \langle v, s' \rangle )$;
		\item $(\langle e_2, s \rangle \goesto^\ast \langle v, s' \rangle) \implies (\langle e_1, s \rangle \goesto^\ast \langle v, s' \rangle )$;
	\end{itemize}
\end{definit}

\begin{definit}[Proprietà di congruenza]
	La relazione di equivalenza $\treq$ soddisfa la proprietà della congruenza, in quanto, dati due programmi $e_1$ e $e_2$ qualsiasi che soddisfano $e_1 \treq e_2$, per ogni contesto $C$ e tipo $T'$, se vale che $\type C\left[e_1\right]:T'$ e $\type C\left[e_2\right]:T'$, allora $C\left[e_1\right] \treq C\left[e_2\right]$.
\end{definit}

Diamo qui di seguito alcune leggi basilari sulla trace equivalence.

\begin{thm}[Associatività di ;] Vale:
	\[ e_1;(e_2; e_3) \treq (e_1; e_2);e_3 \] per qualsiasi $\Gamma, T, e_1, e_2$ ed $e_3$ tali per cui $\type e_1:unit, \type e_2:unit$ e $\type e_3:unit$.
\end{thm} \newpage

\begin{thm}[Rimozione di skip] Valgono:
	\begin{itemize}
		\item $e_2 \simeq_{\Gamma_2}^T (skip;e_2)$
		\item $e_1;skip \simeq_{\Gamma_1}^{unit} e_1$
	\end{itemize}
	per qualunque $\Gamma_1, \Gamma_2, T, e_1, e_2$ tali che $\Gamma_2 \vdash e_2:T$ e $\Gamma_1 \vdash e_1:unit$.
\end{thm}

\begin{thm}[if-false]
	\[ \text{if false then }e_1 \text{ else } e_2 \treq e_2 \]
	per qualsiasi $\Gamma, T, e_1, e_2$ tali per cui $\type e_1:T, \type e_2:T$.
\end{thm}

\begin{thm}[if-true]
	\[ \text{if true then }e_1 \text{ else } e_2 \treq e_2 \]
	per qualsiasi $\Gamma, T, e_1, e_2$ tali per cui $\type e_1:T, \type e_2:T$.
\end{thm}

\begin{thm}[Distributività dell'if rispetto a ;]
	\[ (\text{if } e_1 \text{ then }e_2 \text{ else } e_3);e \treq (\text{if }e_1 \text{ then }e_2; e \text{ else }e_3; e) \]
	per qualsiasi $\Gamma, T, e_1, e_2, e_3$ tali che $\type e_1:bool, \type e_2:unit, \type e_3:unit, \type e:T$.
\end{thm}

\begin{thm}[Distributività di ; rispetto all'if]
	\[ e;(\text{if } e_1 \text{ then }e_2 \text{ else }e_3) \treq (\text{if } e;e_1 \text{ then }e_2 \text{ else }e_3) \]
	per qualsiasi $\Gamma, T, e_1, e_2, e_3$ tali che $\type e_1:bool, \type e_2:T, \type e_3:T, \type e:unit$.
\end{thm}

Diamo ora due definizioni più formali di trace equivalence, che considerano la cosa da un altro punto di vista.
\begin{definit}[Simulazione]
	Diciamo che $e_1$ è simulato da $e_2$, indicando $e_1 \sqsubseteq_\Gamma^T e_2$, se:\begin{itemize}
		\item $\type e_1:T$ e $\type e_2:T$ per qualche $T$;
		\item per qualsiasi $s$ con $dom(\Gamma) \subseteq dom(s)$, se $\langle e_1, s\rangle \goesto \langle e_1',s_1' \rangle$ allora esiste un $e_2'$ tale che $\langle e_2, s \rangle \goesto^\ast \langle e_2',s_2' \rangle$, con $e_1' \sqsubseteq_\Gamma^T e_2'$ e $s_1'=s_2'$.
	\end{itemize}
\end{definit}

\begin{definit}[Bisimulazione]
	Diciamo che $e_1$ è bisimile ad $e_2$, indicando $e_1 \approx_\Gamma^T e_2$ se e solo se:\begin{itemize}
		\item $\type e_1:T$ e $\type e_2:T$ per qualche $T$;
		\item per qualsiasi $s$ con $dom(\Gamma) \subseteq dom(s)$, se $\langle e_1, s\rangle \goesto \langle e_1',s_1' \rangle$ allora esiste un $e_2'$ tale che $\langle e_2, s \rangle \goesto^\ast \langle e_2',s_2' \rangle$, con $e_1' \approx_\Gamma^T e_2'$ e $s_1'=s_2'$;
		\item per qualsiasi $s$ con $dom(\Gamma) \subseteq dom(s)$, se $\langle e_2, s\rangle \goesto \langle e_2',s_2' \rangle$ allora esiste un $e_1'$ tale che $\langle e_1, s \rangle \goesto^\ast \langle e_1',s_1' \rangle$, con $e_1' \approx_\Gamma^T e_2'$ e $s_1'=s_2'$.
	\end{itemize}
\end{definit}


\newpage
\section{Concorrenza}
Fino ad ora il nostro focus è stato quello di un ambito di programmazione puramente sequenziale. In realtà i sistemi moderni non viaggiano mai in linea sequenziale, ma sono programmati in ambito concorrente.

La programmazione concorrente può incrementare anche di molto le prestazioni, con alcuni effetti collaterali, quali:
\begin{itemize}
	\item lo spazio degli stati diventa enormemente più ampio e complesso;
	\item si pongono i problemi di \textit{deadlock}, \textit{starvation} e \textit{data race}, che possono portare a comportamenti erronei;
	\item le computazioni possono diventare non deterministiche, a meno non sia imposto un qualche sistema di sincronizzazione;
	\item problemi di comunicazione tra processi con differenti risorse locali (memorie, librerie condivise,...);
	\item problemi legati alla sicurezza.
\end{itemize}

\subsection{Definizione del linguaggio}
Per cominciare, definiamo il linguaggio sul quale si lavorerà: è composto da un linguaggio imperativo banale come in \ref{imp} e alcuni altri costrutti, quali: \begin{align*}
	e &::=\ \dots\ |\ e \vert \vert e \\
	T &::=\ \dots\ |\ proc
\end{align*}

Il linguaggio gode di alcune caratteristiche, quali: \begin{itemize}
	\item la composizione parallela $e\ || e$;
	\item le thread sono anonime, non ritornano valore e non possono essere uccise esternamente;
	\item i processi sono costituiti da un \textit{pool} di thread concorrenti;
	\item la terminazione di thread non può essere osservata direttamente da un programma.
\end{itemize}

Inoltre, come in ogni altro linguaggio concorrente, le thread vengono eseguite in maniera asincrona e possono scrivere e leggere su memoria condivisa, di conseguenza \textbf{si perde la proprietà di determinatezza}.

\subsection{Semantica della composizione parallela}
La semantica della composizione parallela procede come segue: \begin{align*}
	&\inference[(par-L)]{\langle e_1, s\rangle \goesto \langle e_1', s' \rangle}{\langle e_1 \compar e_2,s \rangle \goesto \langle e_1' \compar e_2, s' \rangle} \quad &\inference[(par-R)]{\langle e_2, s\rangle \goesto \langle e_2', s' \rangle}{\langle e_1 \compar e_2,s \rangle \goesto \langle e_1 \compar e_2', s' \rangle} \\ \\
	&\inference[(end-L)]{-}{\langle skip \compar e, s \rangle \goesto \langle e,s \rangle} \quad &\inference[(end-R)]{-}{\langle e \compar skip,s \rangle \goesto \langle e,s \rangle}
	\end{align*}
	
\subsection{Tipaggio della composizione parallela}
Il tipaggio della composizione parallela procede come segue: \begin{align*}
	\inference[(T-sq1)]{\type e_1:unit \quad \type e_2:unit}{\type e_1;e_2:unit} \quad \inference[(T-sq2)]{\type e_1:unit \quad \type e_2:proc}{\type e_1;e_2:proc}
\end{align*}
\begin{align*}
	\inference[(T-par)]{\type e_1:T_1 \quad \type e_2:T_2}{\type e_1 \compar e_2:proc}\ T_1, T_2 \in \lbrace unit, proc \rbrace
\end{align*}

\textbf{Nota:} dire che $\type e_1:unit$ equivale a dire che $e_1$ è single-threaded, mentre se è di tipo $proc$ è multi-threaded.

\subsection{Race conditions}
Le race condition sono un fenomeno che si verifica quando più thread vanno a modificare una zona di memoria condivisa senza un adeguato metodo di accesso, finendo con l'ottenere risultati inconsistenti e mal composti. Il problema risiede nel fatto che l'esecuzione di una thread può essere interrotta anche a metà di un'operazione, che, senza un sistema di sincronizzazione, causa risultati privi di senso. 

È necessario quindi introdurre costrutti di sincronizzazione più sofisticati, che possano garantire l'accesso in mutua esclusione ai dati condivisi di interesse.









\end{document}