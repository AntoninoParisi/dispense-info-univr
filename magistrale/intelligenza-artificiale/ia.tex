\documentclass[a4paper, 11pt]{article}
\usepackage[english, italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[margin=3cm]{geometry}
\usepackage{libertine}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{multicol}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{courier}
\usepackage{wrapfig}
\usepackage{centernot}

\hypersetup{
	hidelinks, 
	colorlinks = true,
	linkcolor = black,
}

\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,calc}
\usetikzlibrary{decorations.pathreplacing}

\lstset {language = C,
	tabsize=2,
	basicstyle=\footnotesize\ttfamily,
	morekeywords={function, then, foreach, treeSearch, loop, insert, insertAll, goalTest,
		makeNode, expand, initialState, DLS, recursiveDLS, end},
	showstringspaces=false
	}
	
\pagestyle{fancy}
\lhead{\nouppercase{\leftmark}}
\rhead{\nouppercase{\rightmark}}
\chead{}
\lfoot{}
\cfoot{\thepage}
\rfoot{}

\newtheorem{definit}{Definizione}[subsection]
\renewcommand{\headrulewidth}{0.4pt}

\renewcommand{\lstlistingname}{Algorithm}

\newcommand{\astar}{$A^\ast$ }

\begin{document}
 \clearpage
 \begin{titlepage}
 	\centering
 	\vspace*{\fill}
 	{\scshape\LARGE Università degli Studi di Verona \par}
 	\vspace{1.5cm}
 	\line(1,0){280} \\
 	{\huge\bfseries Intelligenza Artificiale\par}
 	\line(1,0){280} \\
 	\vspace{0.5cm}
 	{\scshape\Large Riassunto dei principali argomenti\par}
 	\vspace{2cm}
 	{\Large\itshape Davide Bianchi\par}
 	\vspace{1cm}

 	\vspace{5cm}
 	\vspace*{\fill}
 	% Bottom of the page
 	{\large \today\par}
 \end{titlepage}
 \thispagestyle{empty}
\newpage
\tableofcontents
\newpage


\section{Agenti razionali}
\paragraph{Agenti.}
Un agente è semplicemente un'entità che riceve percezioni e produce una risposta con delle azioni. Formalmente un agente è una funzione \[ f:P^\ast \to A \] dove $P^\ast$ è lo storico delle percezioni e $A$ è un insieme di azioni.

Notare che se un agente ha $\vert P \vert$ possibili percezioni in ingresso, dopo $T$ unità di tempo la funzione agente avrà il seguente numero di entries: \[ \sum_{t=1}^{T} \vert P \vert^t  \]

Un agente è in generale una struttura formata da un'architettura fisica e un programma, e prende in input una percezione attuale e ritorna in output l'azione successiva da svolgere. 

Esistono principalmente 4 tipi di agenti (ordinati per generalità crescente): 
\begin{itemize}
	\item agenti \textit{simple-reflex} $ \rightarrow $ agiscono in base alla percezione dell'ambiente;
	\item agenti \textit{reflex} con stato (model based agents) $ \rightarrow $ agiscono in base allo stato, le azioni sono condizionate da regole;
	\item agenti \textit{goal-based} $ \rightarrow $ le azioni sono condizionate in base al goal prefissato, anche qui è presente uno stato che influisce sul raggiungimento del goal. La soluzione al problema viene eseguita ignorando le percezioni;
	\item agenti \textit{utility-based} $ \rightarrow $ le azioni sono condizionate in base ad una utility che rappresenta un valore, si cerca di arrivare nello stato che massimizza questo valore.
\end{itemize}

\paragraph{Performace measure.} La \textit{performance-measure} costituisce una sorta di punteggio che misura il comportamento dell'agente nell'ambiente in cui opera. Quindi, data una performance measure e le percezioni attuale dell'agente, questo sceglie la sequenze di azioni che la massimizzano.

\paragraph{Ambienti.} Un ambiente, ovvero lo spazio in cui l'agente opera, è caratterizzato dai seguenti tratti: \begin{itemize}
	\item Osservabilità (ho sensori con cui osservo);
	\item Determinismo;
	\item Episodicità (non ho bisogno dello storico delle percezioni, mi basta la percezione corrente);
	\item Staticità (l'ambiente non cambia indipendentemente dall'azione dell'agente);
	\item Discretezza;
	\item Presenza di altri agenti (Multi o Single Agent).
\end{itemize}

Il tipo di ambiente ovviamente condiziona il design degli agenti che vi operano.

\newpage
\section{Problemi di ricerca}
Dividiamo i problemi in due macro-categorie:
\begin{itemize}
	\item Deterministici e completamente osservabili, richiedono un singolo stato;
	\item Non osservabili, in tal caso gli agenti non sanno dove la soluzione possa risiedere;
	\item Non deterministici o parzialmente osservabili; problema di contingenza/eventualità (??);
	\item Lo spazio degli stati è sconosciuto (problemi di esplorazione).
\end{itemize}

\subsection{Formulazione di problemi a stato singolo}
Un problema a stato singolo è definito da 4 elementi: \begin{enumerate}
	\item uno stato iniziale;
	\item una funzione successore (insieme di coppie azione-stato successivo);
	\item un test di \textit{goal};
	\item consto del percorso (costo dei singoli step).
\end{enumerate}

Una soluzione è quindi una sequenza di azioni che portano dallo stato iniziale allo stato di goal.




\subsection{Ricerca non informata}
Le strutture dati utilizzate nelle ricerche su alberi, oltre alla struttura dati contenente l'albero, sono le seguenti:
\begin{itemize}
	\item una lista \lstinline|fringe| (una coda FIFO), contenente la \textit{frontiera}, ovvero i nodi foglia disponibili;
	\item una lista \lstinline|closed|, contente i nodi di frontiera espansi in passi precedenti.
\end{itemize}
In generale ogni algoritmo di ricerca su alberi funziona come segue:
\begin{lstlisting}[frame=tb]
function treeSearch(problem, strategy)
	inizializza l'abero di ricerca usando lo stato iniziale del problema;
	loop:
		se non ci sono candidati per l'espansione:
			return failure
		scegli un nodo foglia per l'espansione rispettando strategy;
		se il nodo contiene uno stato goal:
			return solution;
		altrimenti:
			espandi il nodo e aggiungi il nodo risultante all'albero
\end{lstlisting}

\noindent
\textbf{Nota:} un nodo è una struttura dati, uno stato è una rappresentazione fisica di un nodo, non ha stati padre, ecc.

Il metodo generale per eseguire una ricerca sugli alberi è il seguente:
\begin{lstlisting}[frame=tb]
function treeSearch(problem, fringe):
	fringe = insert(makeNode(initialState[problem]), fringe) 
	loop:
		if fringe is empty
			return failure
		if goalTest(problem,state(node))
			return node
		fringe = insertAll(expand(node, problem), fringe)
\end{lstlisting}

Metodo di espansione dei nodi:
\begin{lstlisting}[frame=tb]
	function expand(node, problem):
		successors = {}
		for each action, result in successorFn(problem, state[node]) do
			s = nuovo nodo
			parentNode[s] = node
			action[s] = action
			state[s] = result
			pathCost[s] = pathCost[node] + stepCost(state[node], action, result)
			depth[s] = depth[node] + 1
			aggiungi s ai successors
		return successors
\end{lstlisting}
Una strategia possibile è quella di scegliere l'ordine dei nodi da espandere.\\
Le strategie sono valutate a seconda delle seguenti dimensioni:
\begin{itemize}
	\item \textit{Completezza}: trova sempre una soluzione se essa esiste?
	\item \textit{Complessità} in termini di \textit{tempo}: numero di nodi generati/espansi
	\item \textit{Complessità} in termini di \textit{spazio}: massimo numero di nodi in memoria
	\item \textit{Ottimalità}: trova sempre la soluzione a costo minore?
\end{itemize}
La complessità in termini di tempo e spazio fa affidamento sui seguenti termini:
\begin{itemize}
	\item \textit{b}: massimo fattore di ramificazione del search tree
	\item \textit{d}: profondità della soluzione a costo minimo
	\item \textit{m} massima profondità dello spazio degli stati (può essere $ \infty $)
\end{itemize}

I problemi di ricerca non informata utilizzano solo le informazioni presenti nella definizione del problema. 
\paragraph{Uniform-cost search.} È l'algoritmo più semplice: espande il nodo con il costo di percorso minore. La frontiera è quindi una coda ordinata per costo. Non guarda al numero di nodi espansi ma unicamente al loro costo.

\paragraph{Breadth-first search (BFS).} Espande il nodo non espanso più in superficie. La frontiera è una coda FIFO. Il problema di questo algoritmo è lo \textbf{spazio usato}. Infatti, dal momento che deve tenere ogni nodo in memoria, con grandi alberi occupa molto spazio; inoltre ha complessità $O(b^{d+1})$, sia spazialmente che temporalmente. In particolare la complessità in termini di tempo è data dalla seguente formula:
\[
	1 + b + b^2 + b^3 + \dots + b^d + b(b^d -1)
\]
\begin{figure}[h!]
	\begin{tikzpicture}[scale=.5,every node/.style={scale=0.8}, >=latex]
	\node[draw, circle,fill=gray!30] (A) at (3,4) {A}; \node[draw, circle] (B) at (1,2) {B}; 
	\node[draw, circle] (C) at (5,2) {C}; \node[draw, circle] (D) at (0,0) {D}; \node[draw, circle] (E) at (2,0) {E}; \node[draw, circle] (F) at (4,0) {F}; 
	\node[draw, circle] (G) at (6,0) {G}; 
	\draw (A) -- (B) -- (D); \draw (A) -- (C) -- (F); \draw (C) -- (G); \draw (B) -- (E); 
	\draw[->, ultra thick] ($ (B) +(-1,0) $) -- (B.west) ;
\end{tikzpicture}
\hspace{1cm}
\begin{tikzpicture}[scale=.5,every node/.style={scale=0.8}, >=latex]
	\node[draw, circle,fill=gray!30] (A) at (3,4) {A}; \node[draw, circle,fill=gray!30] (B) at (1,2) {B}; 
	\node[draw, circle] (C) at (5,2) {C}; \node[draw, circle] (D) at (0,0) {D}; \node[draw, circle] (E) at (2,0) {E}; \node[draw, circle] (F) at (4,0) {F}; 
	\node[draw, circle] (G) at (6,0) {G}; 
	\draw (A) -- (B) -- (D); \draw (A) -- (C) -- (F); \draw (C) -- (G); \draw (B) -- (E); 
	\draw[->, ultra thick] ($ (C) +(-1,0) $) -- (C.west) ;
\end{tikzpicture}
\hspace{1cm}
\begin{tikzpicture}[scale=.5,every node/.style={scale=0.8}, >=latex]
	\node[draw, circle,fill=gray!30] (A) at (3,4) {A}; \node[draw, circle,fill=gray!30] (B) at (1,2) {B}; 
	\node[draw, circle,fill=gray!30] (C) at (5,2) {C}; \node[draw, circle] (D) at (0,0) {D}; 
	\node[draw, circle] (E) at (2,0) {E}; \node[draw, circle] (F) at (4,0) {F}; 
	\node[draw, circle] (G) at (6,0) {G};
	\node at ($ (A.east) +(4,0) $) {$ b^0 $}; \node at ($ (C.east) +(2,0) $) {$ b^1 $}; 
	\node at ($ (G.east) +(2.5,0) $) {$ b^2 + (b^2 -1)b $}; 
	\draw (A) -- (B) -- (D); \draw (A) -- (C) -- (F); \draw (C) -- (G); \draw (B) -- (E); 
	\draw[->, ultra thick] ($ (D) +(-1,0) $) -- (D.west) ;
\end{tikzpicture}
	\label{tikz:bfs}
	\caption{BFS}
	\vspace*{-2.5cm}
\end{figure}

\paragraph{Depth-first search (DFS).} Mentre BFS lavora in ampiezza, DFS lavora in profondità, andando ad espandere il nodo non espanso più a fondo possibile. La complessità spaziale è $O(bm)$, che sarebbe ideale se non per il fatto che fallisce in spazi infiniti oppure in spazi con cicli. Temporalmente ha complessità $O(b^m)$, una complessità peggiore quanto più $m$ è maggiore di $d$.
\vspace{.45cm}
\begin{figure}[h!]
	\centering
	\begin{tikzpicture}[scale=.4,every node/.style={scale=0.6}, >=latex]
	\node[draw, circle, fill=gray!30] (A) at (7,6) {A}; \node[draw, circle, fill=black] (B) at (3,4) {B}; 
	\node[draw, circle, fill=gray!30] (C) at (11,4) {C}; 
	\node[draw, circle, fill=black] (D) at (1,2) {D}; \node[draw, circle, fill=black] (E) at (5,2) {E}; 
	\node[draw, circle, fill=gray!30] (F) at (9,2) {F}; \node[draw, circle] (G) at (13,2) {G}; 
	\node[draw, circle, fill=black] (H) at (0,0) {I}; \node[draw, circle, fill=black] (I) at (2,0) {I}; 
	\node[draw, circle, fill=black] (L) at (4,0) {I}; \node[draw, circle, fill=black] (M) at (6,0) {I}; 
	\node[draw, circle, fill=black] (N) at (8,0) {I}; \node[draw, circle] (O) at (10,0) {O}; \node[draw, circle] (P) at (12,0) {P}; \node[draw, circle] (Q) at (14,0) {Q};
	\draw (A) -- (B) -- (D) -- (H); \draw (A) -- (C) -- (F) -- (N); \draw (C) -- (G) -- (Q); \draw (B) -- (E) -- (M); 
	\draw (E) -- (L); \draw (B) -- (E) -- (M); \draw (D) -- (I); \draw (F) -- (O); \draw (G) -- (P);
	\draw[->, ultra thick] ($ (O) +(-1,0) $) -- (O.west) ;
	\end{tikzpicture}
	\label{tikz:dfs}
	\caption{DFS}
\end{figure}

\paragraph{Depth-limited search.} In realtà è solo una variante della DFS, alla quale viene imposto un limite di profondità da raggiungere. La profondità limite, oltre a ridurre lo spazio utilizzato, risolve anche il problema dei cammini infiniti, che nella DFS standard erano il problema più grande che si potesse avere. È anche vero che viene introdotto un altro punto di debolezza, ovvero quello in cui il goal è oltre la profondità limite.

\begin{lstlisting}[frame=tb, caption={Recursive implementation of DLS}]
	function DLS(problem, limit):
		recursiveDLS(makeNode(initialState[problem]), problem, limit)
		
	function recursiveDLS(node, problem, limit):
		cutoffOccurred = false
		if goalTest(problem, state[node]) then return node
		else if depth[node] = limit then return cutoff
		else foreach successor in expand(node, problem) do
			result = recursiveDLS(successor, problem, limit)
			if result = cutoff then cutoffOccurred = true
			else if result != failure then return result
		if cutoffOccurred then return cutoff
		else return failure		
\end{lstlisting}

\paragraph{Iterative-deepening search (IDS).} È una tecnica usata in combinazione con la DLS per trovare il limite minimo necessario al raggiungimento del goal. Lavora su una profondità variabile chiamando ad ogni iterazione la DLS con il limite corrente. Le complessità sono $O(b^d)$ (temporale) e $O(bd)$ (spaziale). La complessità in termini di tempo in particolare è:
\[
	(d+1) b^0 + db^1 + (d-1)b^2 + \dots + b^d
\]

\begin{lstlisting}[frame=tb, caption={IDS}]
	function IDS(problem)
		for depth = 0 to inf do
			result = DLS(proble, depth)
			if result != cutoff then return result
		end
\end{lstlisting}

\paragraph{Confronto tra gli algoritmi.} Presentiamo di seguito un confronto riepilogativo dei vari algoritmi di ricerca su alberi. \\
\begin{center}
	\begin{tabular}{c ccccc}
		\toprule
		\textbf{Criterio} & \textbf{BF} & \textbf{UC} & \textbf{DF} & \textbf{DL} & \textbf{ID} \\
		\midrule
		Completezza & Si$^\ast$ & Si$^{\ast, \dagger}$ & No & Si, se $l \geq d$ & Si$^\ast$ \\
		Tempo & $b^{d+1}$ & $b^{\lceil C^\ast / \epsilon \rceil}$ & $b^m$ & $b^l$ & $b^d$ \\
		Spazio & $b^{d+1}$ & $b^{\lceil C^\ast / \epsilon \rceil}$ & $bm$ & $bl$ & $bd$ \\
		Ottimale & Si$^\star$ & Si & No & Si$^\star$, se $l \geq d$ & Si$^\star$ \\
		\bottomrule
	\end{tabular}
\end{center}
dove: \begin{itemize}
	\item $\ast$: completo se il branching factor è finito;
	\item $\dagger$: completo se uno step ha costo $\geq \epsilon$;
	\item $\star$:ottimale se tutti i costi dei singoli step sono uguali.
\end{itemize}

\subsection{Esempi}
	\paragraph{BFS vs IDS.} prendiamo un albero che abbia le seguenti caratteristiche:
	\begin{itemize}
		\item Sia un albero di ricerca ben bilanciato
		\item Lo stato di goal è l'ultimo ad essere espanso nel suo livello (rightmost)
	\end{itemize}
	Prendiamo, dato l'albero, i seguenti casi
	\begin{multicols}{2}
		\noindent
		$ b = 3,\ d = 3 $ \\
		\textbf{BFS}
		\begin{align*}
			& b^0 + b^1 + \dots + b^d + b(b^d - 1) =\\
			& 3^0 + 3^1 + 3^2 + 3^3 + 3(3^3 -1) = 118
		\end{align*}
		\columnbreak
		
		\noindent
		$ b = 4,\ d = 3 $ \\
		\textbf{IDS}\vspace*{-9pt}
		\begin{align*}
			& b^0(d + 1) + b^1d + \dots + b^d =\\
			& 4^0(3 + 1) + 4^1\cdot 3 + 4^2\cdot 2 + 4^3\cdot 1 = 112
		\end{align*}
	\end{multicols}
	
	Cosa succede se il controllo del goal viene effettuato quando si inserisce nella frontiera invece che quando si rimuove? (come avviene in tree search)\\
	Per l'IDS non cambia nulla, il numero di nodi sarà sempre 112.\\
	Per la BFS, ci si ferma al nodo goal, senza espandere i nodi sottostanti, quindi il costo cala drasticamente: $ b^0 + b^1 + b^2 + b^3 = 40 $

\subsection{Ricerca informata}
Le strategie di ricerca informata utilizzano conoscenze specifiche riguardanti il problema oltre alla definizione dello stesso, pertanto sono più efficienti.
Gli approcci generali sono 2: \begin{itemize}
	\item euristiche greedy best-first;
	\item euristiche su \astar;
\end{itemize}

\paragraph{Greedy best-first.} Questo approccio cerca di espandere il nodo più vicino al goal, usando una funzione di valutazione. La funzione di valutazione è detta \textbf{euristica} ($h(n)$).

La ricerca greedy non è completa (può fallire in caso di cicli). La sua complessità temporale è $O(b^m)$, ma si può migliorare utilizzando euristiche migliori. La complessità spaziale è la stessa, in quanto è necessario tenere in memoria tutti i nodi.

\paragraph{Ricerca con \astar.} L'idea è quella di evitare di espandere percorsi che sono già costosi di suo. La funzione di valutazione in tal caso è così composta: \[ f(n) = g(n) + h(n) \] dove: \begin{itemize}
	\item $f(n)$ è il costo complessivo del percorso attraverso $n$ al goal;
	\item $h(n)$ è il costo stimato fino al goal a partire da $n$;
	\item $g(n)$ è il costo per raggiungere $n$.
\end{itemize}

La ricerca con \astar usa un'euristica ammissibile, ovvero un euristica in cui $h(n) \leq h^\star(n)$, dove $h^\star(n)$ è il costo vero da $n$. Inoltre si richiede che $h(n) \geq 0$, quindi si ha che $h(G) = 0$ per ogni goal.

\astar è completo, però deve tenere tutti i nodi in memoria e ha complessità esponenziale nell'errore relativo di $h$ per la lunghezza della soluzione. Inoltre si può dimostrare che \astar è ottimale.

\subsection{Caratteristiche delle funzioni euristiche}
Un'euristica si dice consistente se si ha che $h(n) \leq c(n,a,n') + h(n')$.
\begin{wrapfigure}{R}{0.3\textwidth}
	\begin{tikzpicture}
	\node[draw, circle] (a) at (0,0) {$n$};
	\node[draw, circle] (b) at (0,-2) {$n'$};
	\node[draw, circle] (c) at (2,-4) {$G$};
	\draw[->,>=stealth] (a) -- (b) node[midway,left]{$c(n,a,n')$};
	\draw[->,>=stealth](b) -- (c) node[midway,left]{$h(n')$};
	\draw[->,>=stealth] (a) -- (c)node[midway,right]{$h(n)$};
	\end{tikzpicture}
\end{wrapfigure}

È importante notare che 
\begin{align*} 
	\text{consistenza} &\implies \text{ammissibilità} \\ 
	\text{ammissibilità} &\centernot\implies \text{consistenza}  
\end{align*}

Inoltre si definisce un'euristica dominante $h_2$ se vale che, $\forall n$ \[ h_2(n) \geq h_1(n) \]
L'euristica dominante è sempre migliore dal punto di vista prestazionale.

\newpage
\section{Constraint reasoning}
\subsection{Problemi combinatori}
Portiamo come principale categoria di problemi risolvibili tramite reti a vincoli i problemi combinatori, ovvero quei problemi dei quali si deve scegliere la soluzione migliore tra le molti possibili.
Alcuni di questi problemi sono i problemi di decisione e di ottimizzazione.

Ogni problema combinatorio può essere formulato come, dati un insieme di variabili e domini, la ricerca dei valori delle variabili per i quali vale una certa relazione.

\subsection{Reti a vincoli}
Una rete a vincoli è una struttura rappresentata come segue: \begin{itemize}
	\item un insieme di variabili $X = \lbrace x_1, x_2, \dots, x_n \rbrace$;
	\item un insieme di domini $D = \lbrace D_1, D_2, \dots, D_n \rbrace$;
	\item insieme di vincoli $(S_i, R_i)$
	\end{itemize}
Si noti che un vincolo è una coppia $(S_i, R_i)$ dove $S_i$ è una o più variabili $S_i \subseteq X$, mentre $R_i$ è un sottoinsieme del prodotto cartesiano in $S_i$.

La soluzione di una rete a vincoli è l'assegnamento di tutte le variabili in modo tale che tutti i vincoli siano soddisfatti.

\textbf{Nota: }una soluzione parziale (ovvero un parziale assegnamento delle variabili) potrebbe non essere un sottoinsieme dell'assegnamento facente parte della soluzione.

\paragraph{Esempio.}
Il problema del \textit{map-colouring} è l'esempio più indicato. In poche parole in una mappa ogni regione deve avere colore diverso dalle regioni adiacenti.

Supponendo di avere 5 regioni $r_1, ..., r_5$, costruiamo il grafo dei vincoli. Le regioni confinanti dovranno essere collegate tra loro da un arco per rappresentare il vincolo del \textit{non avere lo stesso colore}.

Ogni vincolo sarà così formato (ne diamo solo uno di esempio, gli altri sono analoghi): \[ C_1 = (\lbrace r_1, r_2 \rbrace, r_1 \neq r_2) \]

\begin{center}
	\begin{tikzpicture}
	\node[draw, circle] (a) at (0,-1.7) {$r_1$};
	\node[draw, circle] (b) at (1,0) {$r_2$};
	\node[draw, circle] (c) at (0,-3) {$r_3$};
	\node[draw, circle] (d) at (2,-2) {$r_4$};
	\node[draw, circle] (e) at (4,-2) {$r_5$};
	\draw (b)--(d)--(a);
	\draw (b)--(e)--(d);
	\draw (a)--(c)--(d);
	\draw (a)--(b)node[midway,left]{$C_1$};
	\end{tikzpicture}
\end{center}


Definiamo due nuovi tipi di grafo, ovvero il grafo \textbf{primale} e quello \textbf{duale}.
Il grafo primale ha come nodi le variabili e come archi i vincoli, mentre quello duale è esattamente il contrario: ha come nodi i vincoli, mentre come archi ha le variabili comuni ai vincoli collegati.

\subsection{Forzatura di vincoli e propagazione}
Quando si parla di soluzioni di reti a vincoli, le tecniche risolutive più utilizzate sono quelle basate su: \begin{itemize}
	\item \textit{inferenza}: generazione di nuovi vincoli a partire da quelli già esistenti;
	\item \textit{ricerca}: ricerca della soluzione per tentativi/backtracking.
\end{itemize}

L'idea del backtracking è quella di, scelta una variabile, aggiungere un nuovo vincolo su quella variabile e tentare di risolvere il resto del problema. L'assegnamento parziale di una variabile può comunque violare alcuni vincoli del problema, violando la consistenza del vincolo. In tal caso si fa backtracking per tornare alla situazione precedente e procedere per un'altra via.

\subsubsection{Consistency}
Lo scopo della \textit{constraint inference} è  quello di generare reti più forti con uno spazio di ricerca più piccolo, quindi di migliorare prestazionalmente la ricerca della soluzione. Grazie alla propagazione di nuovi vincoli è possibile ridurre lo spazio di valori accettabili da una sola variabile che a sua volta riduce lo spazio di un'altra variabile ecc.

\paragraph{Node consistency.} Una variabile $x_i$ del dominio $D_i$ è \textit{node-consistent} se ogni suo valore all'interno del dominio soddisfa ogni vincolo unario. In generale, se una variabile non è \textit{node-consistent}, si possono rimuovere tutti i suoi valori nel dominio che non soddisfano tutti i vincoli unari per quella variabile. 

Il nuovo dominio della variabile diventa un dominio $D'_i$ tale per cui: \[ D_i' = D_i \setminus \lbrace v \vert \exists C = \lbrace \langle x_i \rangle, R_{x_i} \rbrace \wedge v \notin R_{x_i}  \rbrace\]

In tal modo il nuovo dominio conterrà solo valori che soddisfano tutti i vincoli, e quelli esclusi non potranno far parte della soluzione.

\paragraph{Arc consistency.} Date due variabili $x_i$ e $x_j$, diciamo che $x_i$ è \textit{arc-consistent} rispetto a $x_j$ se vale che \[ \forall a_i \in D_i\ \exists a_j \in D_j \vert (a_i, a_j) \in R_{x_i, x_j} \]
Da questo si conclude che $R_{x_i, x_j}$ è  \textit{arc-consistent} se $x_i$ è arc-consistent rispetto a $x_j$ e viceversa.

Diamo qui di seguito gli algoritmi possibili per verificare l'\textit{arc-consistency}.
\subparagraph{AC1.}L'algoritmo \textbf{AC1} ha complessità $O(nek^3)$, dove $n$ sono i nodi, $e$ gli archi e $k$ è il massimo numero di valori in un dominio. La procedura di revising è la rimozione dei valori in un dominio per i quali non ha arc-consistency rispetto ad un secondo dominio.

\begin{lstlisting}[escapeinside={(*}{*)}]
repeat
	for all Pairs (*$x_i, x_j$*) that participate in a constraint do
		Revise((*$(x_i),x_j$*));
		Revise((*$(x_j),x_i$*));
	end for
until no domain is changed
	\end{lstlisting}
	
\textbf{Nota}: AC1 termina sempre, e mantiene l'arc-consistency. Se la rete è vuota, non esiste alcuna soluzione.
	
\subparagraph{AC3.} L'algoritmo \textbf{AC3} ha complessità $O(ek^3)$ e procede come segue:\begin{lstlisting}[escapeinside={(*}{*)}]
for all every pairs (*$x_i, x_j$*) that participate in a constraint (*$R_{x_i, x_j} \in R$*) do
	Q = Q (*$\cup \lbrace (x_i, x_j), (x_j, x_i) \rbrace$ *)
end for

while Q (*$\neq \lbrace \rbrace$*) do
	pop (*$(x_i, x_j)$*) from Q
	REVISE((*$(x_i),x_j$*))
	if (*$D_i$*) changed then
		Q = Q (*$\cup \lbrace (x_k, x_i), k\neq i, k\neq j \rbrace$ *)
	end if
end while
\end{lstlisting}

\subparagraph{Domini vuoti.} Nel caso in cui un dominio sia vuoto, si ha un problema inconsistente (ovvero non si ha soluzione). Al contrario, il fatto che non tutti i domini siano vuoti non implica che il problema sia consistente. Il principale punto debole dell'arc-consistency sta nel fatto che lavora solamente su vincoli binari e vincoli con un singolo dominio.

\paragraph{Path consistency.} È un'evoluzione dell'arc-consistency che utilizza triple di variabili. Una coppia di variabili si dice \textit{path-consistent} in relazione ad una terza variabile quando, per ogni assegnamento $x_i = a, x_j = b$ esiste un valore per $x_m$ tale per cui sono soddisfatti i vincoli $(x_i, x_m)$ e $(x_m, x_j)$.
Se i valori cercati violano i vincoli sulla terza variabile, allora tali valori non possono far parte della soluzione, ma \textbf{non possono essere rimossi dai loro domini}.

Quando una coppia di valori $(x=a, y=b)$ non è path-consistent rispetto a $z$ non viene rimossa alcuna soluzione: infatti viene rimossa la \textit{coppia} di valori dalla soluzione, ma non vengono rimossi i valori dai rispettivi domini, in quanto questi potrebbero far parte di altre soluzioni, seppur in coppie differenti da quella scartata.

Per forzare la path-consistency si usa l'algoritmo PC-2 (molto simile a AC-3), che però è computazionalmente più complesso ($O(n^3k^5)$) in quanto lavora su triple.

\paragraph{i-consistency.} La \textit{i-consistency} è un'estensione del concetto nato con l'arc-consistency e la path-consistency che si estende a reti di $i-1$ variabili.

Diciamo che una rete è \textit{i-consistent} quando esiste un valore per un assegnamento per le variabili per il quale un valore consistente può sempre essere assegnato alla i-esima variabile.

Inoltre si definisce una rete come \textit{strongly-consistent} se vale che la rete $R$ è j-consistent per ogni $j \leq i$.

\subsection{Tree decomposition}
Il processo di tree-decomposition è applicato quando da reti cicliche si vuole passare a reti acicliche, in quanto l'inferenza su queste reti è molto più efficiente. 

\paragraph{Ipergrafi.}Introduciamo il concetto base di ipergrafo.
\begin{definit}[Ipergrafo]
	Un ipergrafo è una struttura $G= \langle V, S \rangle$ dove $V$ è un insieme di nodi e $S$ è un insieme di iperarchi, ovvero un insieme $S = \lbrace S_1, S_2, \dots, S_n \rbrace$ tale che $S_i \subseteq V$.
\end{definit}

Il \textit{grafo primale} di un ipergrafo è un grafo in cui i nodi sono i vertici e due vertici sono collegati tra loro solo se appaiono nello stesso iperarco.  Nel \textit{grafo duale} di un ipergrafo invece, i nodi sono gli iperarchi e due nodi sono collegati se e solo se condividono almeno un vertice (gli archi sono etichettati con i vertici condivisi tra gli stessi).

Ogni rete a vincoli può essere rappresentata tramite un ipergrafo. Infatti:
\begin{align*}
	\text{La rete a vincoli }\mathcal{R} &= \lbrace X, D, C \rbrace \text{ con } C= \lbrace R_{S_1}, R_{S_2}, \dots, R_{S_n} \rbrace \\
	\text{Il relativo ipergrafo } H_\mathcal{R} &= (X,H)  \text{ con } H = \lbrace S_1, S_2, \dots, S_n \rbrace \\
	\text{Il grafo duale } H_\mathcal{R}^d &= (H, E) \text{ con } \langle S_i, S_j \rangle \in E \text{ se e solo se } S_i \cap S_j \neq \lbrace \rbrace\\
\end{align*}

\subsubsection{Reti acicliche} 
I concetti principali relativi alle reti acicliche sono i seguenti.
\begin{definit}[Sottografo]
	Definiamo come sottografo di un grafo il grafo $G' = (V, E')$ tale per cui $E' \subseteq E$.
\end{definit}

\begin{definit}[Running intersection property]
	Dato $G$ come grafo duale di un ipergrafo, il suo sottografo $G'$ soddisfa la running intersection property se tra nodi qualsiasi di $G'$ che condividano una variabile esiste un percorso di archi etichettati con almeno la variabile condivisa.
\end{definit}

\begin{definit}[Join graph]
	Il join graph è un sottografo $G'$ di un grafo duale $G$ di un ipergrafo tale per cui $G'$ soddisfa la running intersection property.
\end{definit}

Definiamo inoltre i concetti di \textit{join-tree}, ovvero un \textit{join-graph} aciclico, e il concetto di \textit{iperalbero}, ovvero un ipergrafo il cui grafo duale ha un join-tree.

Concludiamo definendo una \textit{rete aciclica come una rete il cui ipergrafo è un iperalbero}. 
Per risolvere la rete è sufficiente risolvere l'albero con l'algoritmo \textit{tree-solver}, ma è necessario prima sapere come fare a determinare se una rete è aciclica. I principali metodi per eseguire questa verifica sono la \textit{primal-based recognition} e la \textit{dual-based recognition}.

\paragraph{Dual-based recognition.} \textit{Idea di base:} se un ipergrafo ammette un join-tree, allora ogni massimo spanning-tree del suo grafo duale è un join-tree.

La procedura da seguire è la seguente: \begin{itemize}
	\item Construire il grafo duale dell'ipergrafo;
	\item Determinare un maximum spanning tree (usando come peso il numero di variabili condivise);
	\item Controllare se l'hypertree è un join-tree.
\end{itemize}

\paragraph{Primal based-recognition.} \textit{Idea di base:} un ipergrafo ammette un join-tree se valogono le proprietà di \textbf{cordalità} e di \textbf{conformalità}.
\begin{definit}[Conformità]
	Un grafo primale si dice conforme ad un ipergrafo se esiste una corrispondenza uno-a-uno tra clicche massimali e scoping dei vincoli.
\end{definit}

\begin{definit}[Cordalità]
	Un grafo primale si dice cordale se ogni ciclo di lunghezza almeno 4 ha una corda, ovvero un arco che collega due vertici non adiacenti nel ciclo stesso.
\end{definit}

La verifica di queste due proprietà viene eseguita in maniera efficiente se viene usato un \textbf{ordine di massima cardinalità}. Il grafo quindi risulta essere cordale quando in un ordine di massima cardinalità ogni vertice e i suoi predecessori formano una clicca. 

La procedura da applicare è quindi la seguente:\begin{itemize}
	\item Costruire un ordine di massima cardinalità;
	\item Testare se il grafo è cordale (vedi sopra);
	\item Testare se il grafo è conforme (estraendo la clicca massimale e verificando la conformalità).
\end{itemize}

\paragraph{Join-tree clustering.} La procedura del clustering consiste nell'accorpare vincoli per ottenere una sttruttura ad albero. Lo scopo dell'ottenere una struttura ad albero consente di risolvere in maniera più efficace la rete, usando l'algoritmo di \textit{tree-solving}.

Per generare un join-tree si usa il seguente metodo:
\begin{itemize}
	\item Si sceglie un ordine delle variabili;
	\item Si crea un grafo indotto per il quale valga la RIP;
	\item Si crea un join-tree \begin{itemize}
		\item Identificare tutte le clicche massimali $C_1, C_2, \dots, C_t$ nel grafo indotto;
		\item Si crea una struttura ad albero con le clicche (ovvero si crea un maximum-spanning-tree dove i pesi sono i numeri di variabili condivise);
	\end{itemize}
	\item Si allocano i vincoli af ogni clicca che contenga il relativo scope $P_i$ associato alla relativa clicca $C_i$;
	\item Si risolve ogni problema $P_i$ ricavando il relativo insieme di soluzioni $R_i'$;
	\item La soluzione è $C' = \lbrace R_1', \dots, R_t' \rbrace $.
\end{itemize}

\subparagraph{Generazione del grafo indotto.} Seguendo l'ordine inverso delle variabili si calcolano gli antenati di ogni variabile. Poi Per ogni variabile si verifica se forma una clicca (in caso si può forzare la cordalità aggiungendo archi).

\subparagraph{Complessità e osservazioni finali.} La complessità di JTC è dominata dal determinare la soluzione per ogni sottoproblema, che è esponenziale nella dimensione della clicca. Notare che l'ordine delle variabili usato per JTC è fondamentale, e trovare l'ordine migliore è estremamente difficile.

Al termine della risoluzione di ogni sottoproblema, si applica tree-solver per determinare la soluzione globale.

\subsection{Constraint optimization problems}
Si parla di reti di costo quando si ha a che fare con massimizzazioni o minimizzazioni di funzioni di costo. Una rete di costo è una rete a vincoli con una funzione di costo applicata su di essa. Lo scopo è quello di trovare un'allocazione delle variabili che massimizzi o minimizzi la funzione di costo.

I metodi risolutivi per le reti di costo sono: \begin{itemize}
	\item Backtracking con branch \& bound;
	\item Programmazione dinamica.
\end{itemize}

\paragraph{Backtracking con branch \& bound.} L'idea di base del backtracking è di trovare progressivamente la soluzione migliore sulla base di una soluzione parziale, e di sfruttare la soluzione parziale per "sfoltire" l'albero di ricerca.

La pulizia dell'albero di ricerca (supponendo di stare massimizzando una funzione di costo), mantenendo un lower bound. Infatti ogni soluzione trovata minore del lower bound può essere tranquillamente scartata, in quanto non ha senso proseguire lungo un valore che è minore di quello massimo trovato finora.

\newpage
\section{Incertezza e reti Bayesiane}
\subsection{Probabilità e indipendenza condizionale}
L'incertezza è rappresentata tramite un valore probabilistico. 
Due variabili aleatorie $A$ e $B$ si dicono indipendenti se vale che: \begin{itemize}
	\item $P(A \vert B) = P(A) $;
	\item $P(B \vert A) = P(B) $;
	\item $P(A,B) = P(A)P(B)$
\end{itemize}


Note:\begin{align*}
	\text{Prob. composta} \quad P(a \vert b) &= \frac{P(a \wedge b)}{P(b)} \\
	\text{Regola di Bayes} \quad P(a \vert b) &= \frac{P(b \vert a) P(a)}{P(b)} \\
	\text{Naive Bayes model} \quad P(c, e_1, \dots, e_k) &= P(c) \prod_{1}^{i} P(e_i \vert c)
\end{align*}

\subsection{Reti Bayesiane}
Una rete bayesiana è un grafo normalissimo, dove ogni arco $\langle u, v\rangle$ rappresenta il fatto che la variabile $u$ \emph{ha una qualche influenza} sulla variabile $v$.








\end{document}