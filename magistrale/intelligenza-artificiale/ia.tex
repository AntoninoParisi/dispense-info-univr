\documentclass[a4paper, 11pt]{article}
\usepackage[english, italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[margin=3cm]{geometry}
\usepackage{libertine}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{courier}
\usepackage{wrapfig}
\usepackage{centernot}

\hypersetup{
	hidelinks, 
	colorlinks = true,
	linkcolor = black,
}

\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,calc}
\usetikzlibrary{decorations.pathreplacing}

\lstset {language = C,
	tabsize=2,
	basicstyle=\footnotesize\ttfamily,
	morekeywords={function, then, treeSearch, loop, insert, insertAll, goalTest,
		makeNode, expand, initialState, DLS, recursiveDLS, end},
	showstringspaces=false
	}
	
\pagestyle{fancy}
\lhead{\nouppercase{\leftmark}}
\rhead{\nouppercase{\rightmark}}
\chead{}
\lfoot{}
\cfoot{\thepage}
\rfoot{}
\renewcommand{\headrulewidth}{0.4pt}

\renewcommand{\lstlistingname}{Algorithm}

\newcommand{\astar}{$A^\ast$ }

\begin{document}
 \clearpage
 \begin{titlepage}
 	\centering
 	\vspace*{\fill}
 	{\scshape\LARGE Università degli Studi di Verona \par}
 	\vspace{1.5cm}
 	\line(1,0){280} \\
 	{\huge\bfseries Intelligenza Artificiale\par}
 	\line(1,0){280} \\
 	\vspace{0.5cm}
 	{\scshape\Large Riassunto dei principali argomenti\par}
 	\vspace{2cm}
 	{\Large\itshape Davide Bianchi\par}
 	\vspace{1cm}

 	\vspace{5cm}
 	\vspace*{\fill}
 	% Bottom of the page
 	{\large \today\par}
 \end{titlepage}
 \thispagestyle{empty}
\newpage
\tableofcontents
\newpage


\section{Agenti razionali}
\paragraph{Agenti.}
Un agente è semplicemente un'entità che riceve percezioni e produce una risposta con delle azioni. Formalmente un agente è una funzione \[ f:P^\ast \to A \] dove $P^\ast$ è lo storico delle percezioni e $A$ è un insieme di azioni.

Notare che se un agente ha $\vert P \vert$ possibili percezioni in ingresso, dopo $T$ unità di tempo la funzione agente avrà il seguente numero di entries: \[ \sum_{t=1}^{T} \vert P \vert^t  \]

Un agente è in generale una struttura formata da un'architettura fisica e un programma, e prende in input una percezione attuale e ritorna in output l'azione successiva da svolgere. 

Esistono principalmente 4 tipi di agenti (ordinati per generalità crescente): 
\begin{itemize}
	\item agenti \textit{simple-reflex} $ \rightarrow $ agiscono in base alla percezione dell'ambiente;
	\item agenti \textit{reflex} con stato (model based agents) $ \rightarrow $ agiscono in base allo stato, le azioni sono condizionate da regole;
	\item agenti \textit{goal-based} $ \rightarrow $ le azioni sono condizionate in base al goal prefissato, anche qui è presente uno stato che influisce sul raggiungimento del goal. La soluzione al problema viene eseguita ignorando le percezioni;
	\item agenti \textit{utility-based} $ \rightarrow $ le azioni sono condizionate in base ad una utility che rappresenta un valore, si cerca di arrivare nello stato che massimizza questo valore.
\end{itemize}

\paragraph{Performace measure.} La \textit{performance-measure} costituisce una sorta di punteggio che misura il comportamento dell'agente nell'ambiente in cui opera. Quindi, data una performance measure e le percezioni attuale dell'agente, questo sceglie la sequenze di azioni che la massimizzano.

\paragraph{Ambienti.} Un ambiente, ovvero lo spazio in cui l'agente opera, è caratterizzato dai seguenti tratti: \begin{itemize}
	\item Osservabilità (ho sensori con cui osservo);
	\item Determinismo;
	\item Episodicità (non ho bisogno dello storico delle percezioni, mi basta la percezione corrente);
	\item Staticità (l'ambiente non cambia indipendentemente dall'azione dell'agente);
	\item Discretezza;
	\item Presenza di altri agenti (Multi o Single Agent).
\end{itemize}

Il tipo di ambiente ovviamente condiziona il design degli agenti che vi operano.

\newpage
\section{Problemi di ricerca}
Dividiamo i problemi in due macro-categorie:
\begin{itemize}
	\item Deterministici e completamente osservabili, richiedono un singolo stato;
	\item Non osservabili, in tal caso gli agenti non sanno dove la soluzione possa risiedere;
	\item Non deterministici o parzialmente osservabili; problema di contingenza/eventualità (??);
	\item Lo spazio degli stati è sconosciuto (problemi di esplorazione).
\end{itemize}

\subsection{Formulazione di problemi a stato singolo}
Un problema a stato singolo è definito da 4 elementi: \begin{enumerate}
	\item uno stato iniziale;
	\item una funzione successore (insieme di coppie azione-stato successivo);
	\item un test di \textit{goal};
	\item consto del percorso (costo dei singoli step).
\end{enumerate}

Una soluzione è quindi una sequenza di azioni che portano dallo stato iniziale allo stato di goal.




\subsection{Ricerca non informata}
Le strutture dati utilizzate nelle ricerche su alberi, oltre alla struttura dati contenente l'albero, sono le seguenti:
\begin{itemize}
	\item una lista \lstinline|fringe| (una coda FIFO), contenente la \textit{frontiera}, ovvero i nodi foglia disponibili;
	\item una lista \lstinline|closed|, contente i nodi di frontiera espansi in passi precedenti.
\end{itemize}
In generale ogni algoritmo di ricerca su alberi funziona come segue:
\begin{lstlisting}[frame=tb]
function treeSearch(problem, strategy)
	inizializza l'abero di ricerca usando lo stato iniziale del problema;
	loop:
		se non ci sono candidati per l'espansione:
			return failure
		scegli un nodo foglia per l'espansione rispettando strategy;
		se il nodo contiene uno stato goal:
			return solution;
		altrimenti:
			espandi il nodo e aggiungi il nodo risultante all'albero
\end{lstlisting}

\noindent
\textbf{Nota:} un nodo è una struttura dati, uno stato è una rappresentazione fisica di un nodo, non ha stati padre, ecc.

Il metodo generale per eseguire una ricerca sugli alberi è il seguente:
\begin{lstlisting}[frame=tb]
function treeSearch(problem, fringe):
	fringe = insert(makeNode(initialState[problem]), fringe) 
	loop:
		if fringe is empty
			return failure
		if goalTest(problem,state(node))
			return node
		fringe = insertAll(expand(node, problem), fringe)
\end{lstlisting}

Metodo di espansione dei nodi:
\begin{lstlisting}[frame=tb]
	function expand(node, problem):
		successors = {}
		for each action, result in successorFn(problem, state[node]) do
			s = nuovo nodo
			parentNode[s] = node
			action[s] = action
			state[s] = result
			pathCost[s] = pathCost[node] + stepCost(state[node], action, result)
			depth[s] = depth[node] + 1
			aggiungi s ai successors
		return successors
\end{lstlisting}
Una strategia possibile è quella di scegliere l'ordine dei nodi da espandere.\\
Le strategie sono valutate a seconda delle seguenti dimensioni:
\begin{itemize}
	\item \textit{Completezza}: trova sempre una soluzione se essa esiste?
	\item \textit{Complessità} in termini di \textit{tempo}: numero di nodi generati/espansi
	\item \textit{Complessità} in termini di \textit{spazio}: massimo numero di nodi in memoria
	\item \textit{Ottimalità}: trova sempre la soluzione a costo minore?
\end{itemize}
La complessità in termini di tempo e spazio fa affidamento sui seguenti termini:
\begin{itemize}
	\item \textit{b}: massimo fattore di ramificazione del search tree
	\item \textit{d}: profondità della soluzione a costo minimo
	\item \textit{m} massima profondità dello spazio degli stati (può essere $ \infty $)
\end{itemize}

I problemi di ricerca non informata utilizzano solo le informazioni presenti nella definizione del problema. 
\paragraph{Uniform-cost search.} È l'algoritmo più semplice: espande il nodo con il costo di percorso minore. La frontiera è quindi una coda ordinata per costo. Non guarda al numero di nodi espansi ma unicamente al loro costo.

\paragraph{Breadth-first search (BFS).} Espande il nodo non espanso più in superficie. La frontiera è una coda FIFO. Il problema di questo algoritmo è lo \textbf{spazio usato}. Infatti, dal momento che deve tenere ogni nodo in memoria, con grandi alberi occupa molto spazio; inoltre ha complessità $O(b^{d+1})$, sia spazialmente che temporalmente.

\begin{figure}[h!]
	\begin{tikzpicture}[scale=.5,every node/.style={scale=0.8}, >=latex]
	\node[draw, circle] (A) at (3,4) {A}; \node[draw, circle] (B) at (1,2) {B}; \node[draw, circle] (C) at (5,2) {C}; 
	\node[draw, circle] (D) at (0,0) {D}; \node[draw, circle] (E) at (2,0) {E}; \node[draw, circle] (F) at (4,0) {F}; 
	\node[draw, circle] (G) at (6,0) {G}; 
	\draw (A) -- (B) -- (D); \draw (A) -- (C) -- (F); \draw (C) -- (G); \draw (B) -- (E); 
	\draw[->, ultra thick] ($ (B) +(-1,0) $) -- (B.west) ;
\end{tikzpicture}
\hspace{1cm}
\begin{tikzpicture}[scale=.5,every node/.style={scale=0.8}, >=latex]
	\node[draw, circle] (A) at (3,4) {A}; \node[draw, circle] (B) at (1,2) {B}; \node[draw, circle] (C) at (5,2) {C}; 
	\node[draw, circle] (D) at (0,0) {D}; \node[draw, circle] (E) at (2,0) {E}; \node[draw, circle] (F) at (4,0) {F}; 
	\node[draw, circle] (G) at (6,0) {G}; 
	\draw (A) -- (B) -- (D); \draw (A) -- (C) -- (F); \draw (C) -- (G); \draw (B) -- (E); 
	\draw[->, ultra thick] ($ (C) +(-1,0) $) -- (C.west) ;
\end{tikzpicture}
\hspace{1cm}
\begin{tikzpicture}[scale=.5,every node/.style={scale=0.8}, >=latex]
	\node[draw, circle] (A) at (3,4) {A}; \node[draw, circle] (B) at (1,2) {B}; \node[draw, circle] (C) at (5,2) {C}; 
	\node[draw, circle] (D) at (0,0) {D}; \node[draw, circle] (E) at (2,0) {E}; \node[draw, circle] (F) at (4,0) {F}; 
	\node[draw, circle] (G) at (6,0) {G}; 
	\draw (A) -- (B) -- (D); \draw (A) -- (C) -- (F); \draw (C) -- (G); \draw (B) -- (E); 
	\draw[->, ultra thick] ($ (D) +(-1,0) $) -- (D.west) ;
\end{tikzpicture}
	\label{tikz:bfs}
	\caption{BFS}
\end{figure}

\paragraph{Depth-first search (DFS).} Mentre BFS lavora in ampiezza, DFS lavora in profondità, andando ad espandere il nodo non espanso più a fondo possibile. La complessità spaziale è $O(bm)$, che sarebbe ideale se non per il fatto che fallisce in spazi infiniti oppure in spazi con cicli. Temporalmente ha complessità $O(b^m)$, una complessità peggiore quanto più $m$ è maggiore di $d$.

\begin{figure}[h!]
	\centering
	\begin{tikzpicture}[scale=.4,every node/.style={scale=0.6}, >=latex]
	\node[draw, circle, fill=gray!30] (A) at (7,6) {A}; \node[draw, circle, fill=black] (B) at (3,4) {B}; 
	\node[draw, circle, fill=gray!30] (C) at (11,4) {C}; 
	\node[draw, circle, fill=black] (D) at (1,2) {D}; \node[draw, circle, fill=black] (E) at (5,2) {E}; 
	\node[draw, circle, fill=gray!30] (F) at (9,2) {F}; \node[draw, circle] (G) at (13,2) {G}; 
	\node[draw, circle, fill=black] (H) at (0,0) {I}; \node[draw, circle, fill=black] (I) at (2,0) {I}; 
	\node[draw, circle, fill=black] (L) at (4,0) {I}; \node[draw, circle, fill=black] (M) at (6,0) {I}; 
	\node[draw, circle, fill=black] (N) at (8,0) {I}; \node[draw, circle] (O) at (10,0) {O}; \node[draw, circle] (P) at (12,0) {P}; \node[draw, circle] (Q) at (14,0) {Q};
	\draw (A) -- (B) -- (D) -- (H); \draw (A) -- (C) -- (F) -- (N); \draw (C) -- (G) -- (Q); \draw (B) -- (E) -- (M); 
	\draw (E) -- (L); \draw (B) -- (E) -- (M); \draw (D) -- (I); \draw (F) -- (O); \draw (G) -- (P);
	\draw[->, ultra thick] ($ (O) +(-1,0) $) -- (O.west) ;
	\end{tikzpicture}
	\label{tikz:dfs}
	\caption{DFS}
\end{figure}

\paragraph{Depth-limited search.} In realtà è solo una variante della DFS, alla quale viene imposto un limite di profondità da raggiungere. La profondità limite, oltre a ridurre lo spazio utilizzato, risolve anche il problema dei cammini infiniti, che nella DFS standard erano il problema più grande che si potesse avere. È anche vero che viene introdotto un altro punto di debolezza, ovvero quello in cui il goal è oltre la profondità limite.

\begin{lstlisting}[frame=tb, caption={Recursive implementation of DLS}]
	function DLS(problem, limit):
		recursiveDLS(makeNode(initialState[problem]), problem, limit)
		
	function recursiveDLS(node, problem, limit):
		cutoffOccurred = false
		if goalTest(problem, state[node]) then return node
		else if depth[node] = limit then return cutoff
		else for each successor in expand(node, problem) do
			result = recursiveDLS(successor, problem, limit)
			if result = cutoff then cutoffOccurred = true
			else if result != failure then return result
		if cutoffOccurred then return cutoff
		else return failure		
\end{lstlisting}

\paragraph{Iterative-deepening search (IDS).} È una tecnica usata in combinazione con la DLS per trovare il limite minimo necessario al raggiungimento del goal. Lavora su una profondità variabile chiamando ad ogni iterazione la DLS con il limite corrente. Le complessità sono $O(b^d)$ (temporale) e $O(bd)$ (spaziale).

\begin{lstlisting}[frame=tb, caption={IDS}]
	function IDS(problem)
		for depth = 0 to inf do
			result = DLS(proble, depth)
			if result != cutoff then return result
		end
\end{lstlisting}

\paragraph{Confronto tra gli algoritmi.} Presentiamo di seguito un confronto riepilogativo dei vari algoritmi di ricerca su alberi. \\
\begin{center}
	\begin{tabular}{c ccccc}
		\toprule
		\textbf{Criterio} & \textbf{BF} & \textbf{UC} & \textbf{DF} & \textbf{DL} & \textbf{ID} \\
		\midrule
		Completezza & Si$^\ast$ & Si$^{\ast, \dagger}$ & No & Si, se $l \geq d$ & Si$^\ast$ \\
		Tempo & $b^{d+1}$ & $b^{\lceil C^\ast / \epsilon \rceil}$ & $b^m$ & $b^l$ & $b^d$ \\
		Spazio & $b^{d+1}$ & $b^{\lceil C^\ast / \epsilon \rceil}$ & $bm$ & $bl$ & $bd$ \\
		Ottimale & Si$^\star$ & Si & No & Si$^\star$, se $l \geq d$ & Si$^\star$ \\
		\bottomrule
	\end{tabular}
\end{center}
dove: \begin{itemize}
	\item $\ast$: completo se il branching factor è finito;
	\item $\dagger$: completo se uno step ha costo $\geq \epsilon$;
	\item $\star$:ottimale se tutti i costi dei singoli step sono uguali.
\end{itemize}

\subsection{Ricerca informata}
Le strategie di ricerca informata utilizzano conoscenze specifiche riguardanti il problema oltre alla definizione dello stesso, pertanto sono più efficienti.
Gli approcci generali sono 2: \begin{itemize}
	\item euristiche greedy best-first;
	\item euristiche su \astar;
\end{itemize}

\paragraph{Greedy best-first.} Questo approccio cerca di espandere il nodo più vicino al goal, usando una funzione di valutazione. La funzione di valutazione è detta \textbf{euristica} ($h(n)$).

La ricerca greedy non è completa (può fallire in caso di cicli). La sua complessità temporale è $O(b^m)$, ma si può migliorare utilizzando euristiche migliori. La complessità spaziale è la stessa, in quanto è necessario tenere in memoria tutti i nodi.

\paragraph{Ricerca con \astar.} L'idea è quella di evitare di espandere percorsi che sono già costosi di suo. La funzione di valutazione in tal caso è così composta: \[ f(n) = g(n) + h(n) \] dove: \begin{itemize}
	\item $f(n)$ è il costo complessivo del percorso attraverso $n$ al goal;
	\item $h(n)$ è il costo stimato fino al goal a partire da $n$;
	\item $g(n)$ è il costo per raggiungere $n$.
\end{itemize}

La ricerca con \astar usa un'euristica ammissibile, ovvero un euristica in cui $h(n) \leq h^\star(n)$, dove $h^\star(n)$ è il costo vero da $n$. Inoltre si richiede che $h(n) \geq 0$, quindi si ha che $h(G) = 0$ per ogni goal.

\astar è completo, però deve tenere tutti i nodi in memoria e ha complessità esponenziale nell'errore relativo di $h$ per la lunghezza della soluzione. Inoltre si può dimostrare che \astar è ottimale.

\subsection{Caratteristiche delle funzioni euristiche}
Un'euristica si dice consistente se si ha che $h(n) \leq c(n,a,n') + h(n')$.
\begin{wrapfigure}{R}{0.3\textwidth}
	\begin{tikzpicture}
	\node[draw, circle] (a) at (0,0) {$n$};
	\node[draw, circle] (b) at (0,-2) {$n'$};
	\node[draw, circle] (c) at (2,-4) {$G$};
	\draw[->,>=stealth] (a) -- (b) node[midway,left]{$c(n,a,n')$};
	\draw[->,>=stealth](b) -- (c) node[midway,left]{$h(n')$};
	\draw[->,>=stealth] (a) -- (c)node[midway,right]{$h(n)$};
	\end{tikzpicture}
\end{wrapfigure}

È importante notare che 
\begin{align*} 
	\text{consistenza} &\implies \text{ammissibilità} \\ 
	\text{ammissibilità} &\centernot\implies \text{consistenza}  
\end{align*}

Inoltre si definisce un'euristica dominante $h_2$ se vale che, $\forall n$ \[ h_2(n) \geq h_1(n) \]
L'euristica dominante è sempre migliore dal punto di vista prestazionale.











\end{document}