\documentclass[a4paper, 11pt]{article}
\usepackage[english, italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[margin=3cm]{geometry}
\usepackage{libertine}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{courier}
\usepackage{wrapfig}
\usepackage{centernot}
\hypersetup{
	hidelinks, 
	colorlinks = true,
	linkcolor = black,
}

\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,calc}
\usetikzlibrary{decorations.pathreplacing}

\lstset {
	tabsize=2,
	basicstyle=\footnotesize\ttfamily
	}

\newcommand{\astar}{$A^\ast$ }

\begin{document}
 \clearpage
 \begin{titlepage}
 	\centering
 	\vspace*{\fill}
 	{\scshape\LARGE Università degli Studi di Verona \par}
 	\vspace{1.5cm}
 	\line(1,0){280} \\
 	{\huge\bfseries Intelligenza Artificiale\par}
 	\line(1,0){280} \\
 	\vspace{0.5cm}
 	{\scshape\Large Riassunto dei principali argomenti\par}
 	\vspace{2cm}
 	{\Large\itshape Davide Bianchi\par}
 	\vspace{1cm}

 	\vspace{5cm}
 	\vspace*{\fill}
 	% Bottom of the page
 	{\large \today\par}
 \end{titlepage}
 \thispagestyle{empty}
\newpage
\tableofcontents
\newpage


\section{Agenti razionali}
\paragraph{Agenti.}
Un agente è semplicemente un'entità che riceve percezioni e produce una risposta con delle azioni. Formalmente un agente è una funzione \[ f:P^\ast \to A \] dove $P^\ast$ è lo storico delle percezioni e $A$ è un insieme di azioni.

Notare che se un agente ha $\vert P \vert$ possibili percezioni in ingresso, dopo $T$ unità di tempo la funzione agente avrà il seguente numero di entries: \[ \sum_{t=1}^{T} \vert P \vert^t  \]

Un agente è in generale una struttura formata da un'architettura fisica e un programma, e prende in input una percezione attuale e ritorna in output l'azione successiva da svolgere. 

Esistono principalmente 4 tipi di agenti: \begin{itemize}
	\item agenti \textit{simple-reflex};
	\item agenti \textit{reflex} con stato;
	\item agenti \textit{goal-based};
	\item agenti \textit{utility-based}.
\end{itemize}

\paragraph{Performace measure.} La \textit{performance-measure} costituisce una sorta di punteggio che misura il comportamento dell'agente nell'ambiente in cui opera. Quindi, data una performance measure e le percezioni attuale dell'agente, questo sceglie la sequenze di azioni che la massimizzano.

\paragraph{Ambienti.} Un ambiente, ovvero lo spazio in cui l'agente opera, è caratterizzato dai seguenti tratti: \begin{itemize}
	\item Osservabilità;
	\item Determinismo;
	\item Episodicità;
	\item Staticità;
	\item Discretezza;
	\item Presenza di altri agenti.
\end{itemize}

Il tipo di ambiente ovviamente condiziona il design degli agenti che vi operano.

\newpage
\section{Problemi di ricerca}
Dividiamo i problemi in due macro-categorie:
\begin{itemize}
	\item Deterministici e completamente osservabili, richiedono un singolo stato;
	\item Non osservabili, in tal caso gli agenti non sanno dove la soluzione possa risiedere;
	\item Non deterministici o parzialmente osservabili; problema di contingenza/eventualità (??);
	\item Lo spazio degli stati è sconosciuto (problemi di esplorazione).
\end{itemize}

\subsection{Formulazione di problemi a stato singolo}
Un problema a stato singolo è definito da 4 elementi: \begin{enumerate}
	\item uno stato iniziale;
	\item una funzione successore (insieme di coppie azione-stato successivo);
	\item un test di \textit{goal};
	\item consto del percorso (costo dei singoli step).
\end{enumerate}

Una soluzione è quindi una sequenza di azioni che portano dallo stato iniziale allo stato di goal.




\subsection{Ricerca non informata}
Le strutture dati utilizzate nelle ricerche su alberi, oltre alla struttura dati contenente l'albero, sono le seguenti:
\begin{itemize}
	\item una lista \lstinline|fringe| (una coda FIFO), contenente la \textit{frontiera}, ovvero i nodi foglia disponibili;
	\item una lista \lstinline|closed|, contente i nodi di frontiera espansi in passi precedenti.
\end{itemize}
In generale ogni algoritmo di ricerca su alberi funziona come segue:
\begin{lstlisting}
function tree-search(problem, strategy)
	inizializza l'abero di ricerca usando lo stato iniziale del problema;
	loop:
		se non ci sono candidati per l'espansione:
			return failure
		scegli un nodo foglia per l'espansione rispettando strategy;
		se il nodo contiene uno stato goal:
			return solution;
		altrimenti:
			espandi il nodo e aggiungi il nodo risultante all'albero
\end{lstlisting}

\noindent
\textbf{Nota:} un nodo è una struttura dati, uno stato è una rappresentazione fisica di un nodo, non ha stati padre, ecc.

Il metodo generale per eseguire una ricerca sugli alberi è il seguente:
\begin{lstlisting}
function tree-search(problem, fringe):
	fringe = insert(make-node(initial-state[problem]), fringe) 
	loop:
		if fringe is empty
			return failure
		if goal-test(problem,state(node))
			return node
		fringe = insert-all(expand(node, problem), fringe)
\end{lstlisting}

I problemi di ricerca non informata utilizzano solo le informazioni presenti nella definizione del problema. 
\paragraph{Uniform-cost search.} È l'algoritmo più semplice: espande il nodo con il costo di percorso minore. La frontiera è quindi una coda ordinata per costo. Non guarda al numero di nodi espansi ma unicamente al loro costo.

\paragraph{Breadth-first search.} Espande il nodo non espanso più in superficie. Il problema di questo algoritmo è lo \textbf{spazio usato}. Infatti, dal momento che deve tenere ogni nodo in memoria, con grandi alberi occupa molto spazio; inoltre ha complessità $O(b^{d+1})$, sia spazialmente che temporalmente.

\paragraph{Depth-first search.} Mentre BFS lavora in ampiezza, DFS lavora in profondità, andando ad espandere il nodo non espanso più a fondo possibile. La complessità spaziale è $O(bm)$, che sarebbe ideale se non per il fatto che fallisce in spazi infiniti oppure in spazi con cicli. Temporalmente ha complessità $O(b^m)$, una complessità peggiore quanto più $m$ è maggiore di $d$.

\paragraph{Depth-limited search.} In realtà è solo una variante della DFS, alla quale viene imposto un limite di profondità da raggiungere. La profondità limite, oltre a ridurre lo spazio utilizzato, risolve anche il problema dei cammini infiniti, che nella DFS standard erano il problema più grande che si potesse avere. È anche vero che viene introdotto un altro punto di debolezza, ovvero quello in cui il goal è oltre la profondità limite.

\paragraph{Iterative-deepening search.} È una tecnica usata in combinazione con la DLS per trovare il limite minimo necessario al raggiungimento del goal. Lavora su una profondità variabile chiamando ad ogni iterazione la DLS con il limite corrente. Le complessità sono $O(b^d)$ (temporale) e $O(bd)$ (spaziale).

\paragraph{Confronto tra gli algoritmi.} Presentiamo di seguito un confronto riepilogativo dei vari algoritmi di ricerca su alberi. \\
\begin{center}
	\begin{tabular}{c ccccc}
		\toprule
		\textbf{Criterio} & \textbf{BF} & \textbf{UC} & \textbf{DF} & \textbf{DL} & \textbf{ID} \\
		\midrule
		Completezza & Si$^\ast$ & Si$^{\ast, \dagger}$ & No & Si, se $l \geq d$ & Si$^\ast$ \\
		Tempo & $b^{d+1}$ & $b^{\lceil C^\ast / \epsilon \rceil}$ & $b^m$ & $b^l$ & $b^d$ \\
		Spazio & $b^{d+1}$ & $b^{\lceil C^\ast / \epsilon \rceil}$ & $bm$ & $bl$ & $bd$ \\
		Ottimale & Si$^\star$ & Si & No & Si$^\star$, se $l \geq d$ & Si$^\star$ \\
		\bottomrule
	\end{tabular}
\end{center}
dove: \begin{itemize}
	\item $\ast$: completo se il branching factor è finito;
	\item $\dagger$: completo se uno step ha costo $\geq \epsilon$;
	\item $\star$:ottimale se tutti i costi dei singoli step sono uguali.
\end{itemize}

\subsection{Ricerca informata}
Le strategie di ricerca informata utilizzano conoscenze specifiche riguardanti il problema oltre alla definizione dello stesso, pertanto sono più efficienti.
Gli approcci generali sono 2: \begin{itemize}
	\item euristiche greedy best-first;
	\item euristiche su \astar;
\end{itemize}

\paragraph{Greedy best-first.} Questo approccio cerca di espandere il nodo più vicino al goal, usando una funzione di valutazione. La funzione di valutazione è detta \textbf{euristica} ($h(n)$).

La ricerca greedy non è completa (può fallire in caso di cicli). La sua complessità temporale è $O(b^m)$, ma si può migliorare utilizzando euristiche migliori. La complessità spaziale è la stessa, in quanto è necessario tenere in memoria tutti i nodi.

\paragraph{Ricerca con \astar.} L'idea è quella di evitare di espandere percorsi che sono già costosi di suo. La funzione di valutazione in tal caso è così composta: \[ f(n) = g(n) + h(n) \] dove: \begin{itemize}
	\item $f(n)$ è il costo complessivo del percorso attraverso $n$ al goal;
	\item $h(n)$ è il costo stimato fino al goal a partire da $n$;
	\item $g(n)$ è il costo per raggiungere $n$.
\end{itemize}

La ricerca con \astar usa un'euristica ammissibile, ovvero un euristica in cui $h(n) \leq h^\star(n)$, dove $h^\star(n)$ è il costo vero da $n$. Inoltre si richiede che $h(n) \geq 0$, quindi si ha che $h(G) = 0$ per ogni goal.

\astar è completo, però deve tenere tutti i nodi in memoria e ha complessità esponenziale nell'errore relativo di $h$ per la lunghezza della soluzione. Inoltre si può dimostrare che \astar è ottimale.

\subsection{Caratteristiche delle funzioni euristiche}
Un'euristica si dice consistente se si ha che $h(n) \leq c(n,a,n') + h(n')$.
\begin{wrapfigure}{R}{0.3\textwidth}
	\begin{tikzpicture}
	\node[draw, circle] (a) at (0,0) {$n$};
	\node[draw, circle] (b) at (0,-2) {$n'$};
	\node[draw, circle] (c) at (2,-4) {$G$};
	\draw[->,>=stealth] (a) -- (b) node[midway,left]{$c(n,a,n')$};
	\draw[->,>=stealth](b) -- (c) node[midway,left]{$h(n')$};
	\draw[->,>=stealth] (a) -- (c)node[midway,right]{$h(n)$};
	\end{tikzpicture}
\end{wrapfigure}

È importante notare che 
\begin{align*} 
	\text{consistenza} &\implies \text{ammissibilità} \\ 
	\text{ammissibilità} &\centernot\implies \text{consistenza}  
\end{align*}

Inoltre si definisce un'euristica dominante $h_2$ se vale che, $\forall n$ \[ h_2(n) \geq h_1(n) \]
L'euristica dominante è sempre migliore dal punto di vista prestazionale.











\end{document}